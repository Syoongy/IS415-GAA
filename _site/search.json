[
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Drug abuse is a major issue in Thailand, particularly among its youth. Proximity to the Golden Triangle, a key drug production hub of Indochina, and ongoing infrastructure development have made Thailand a market and transit point for drug trafficking.\nThere are 2.7 million youths using drugs in the country, with around 300,000 aged 15 to 19 in need of treatment. Vocational-school students are disproportionately involved in drug abuse compared to secondary-school students, highlighting deeper social and economic issues. Addressing this problem requires a coordinated response, including law enforcement, public health efforts, and community-based interventions."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#import",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#import",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Import",
    "text": "Import\nWe first want to load in the drug offenses in thailand from 2017 to 2022\n\nthai_drug &lt;- read_csv(\"data/archive/thai_drug_offenses_2017_2022.csv\")\n\nRows: 7392 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): types_of_drug_offenses, province_th, province_en\ndbl (2): fiscal_year, no_cases\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nset.seed(448)\n\n\nclass(thai_drug)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nWe also want to import our shapefile of administrative area 1 in Thailand\n\nthai_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Take-home_EX\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\n\nthai_sf\n\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\nFirst 10 features:\n   Shape_Leng Shape_Area                  ADM1_EN       ADM1_TH ADM1_PCODE\n1    2.417227 0.13133873                  Bangkok  กรุงเทพมหานคร       TH10\n2    1.695100 0.07926199             Samut Prakan    สมุทรปราการ       TH11\n3    1.251111 0.05323766               Nonthaburi         นนทบุรี       TH12\n4    1.884945 0.12698345             Pathum Thani        ปทุมธานี       TH13\n5    3.041716 0.21393797 Phra Nakhon Si Ayutthaya พระนครศรีอยุธยา       TH14\n6    1.739908 0.07920961                Ang Thong        อ่างทอง       TH15\n7    5.693342 0.54578838                 Lop Buri          ลพบุรี       TH16\n8    1.778326 0.06872655                Sing Buri         สิงห์บุรี       TH17\n9    2.896316 0.20907828                 Chai Nat         ชัยนาท       TH18\n10   4.766446 0.29208711                 Saraburi         สระบุรี       TH19\n   ADM1_REF ADM1ALT1EN ADM1ALT2EN ADM1ALT1TH ADM1ALT2TH  ADM0_EN   ADM0_TH\n1      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n2      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n3      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n4      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n5      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n6      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n7      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n8      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n9      &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n10     &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย\n   ADM0_PCODE       date    validOn    validTo                       geometry\n1          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.6139 13...\n2          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.7306 13...\n3          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3415 14...\n4          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.8916 14...\n5          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.5131 14...\n6          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3332 14...\n7          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((101.3453 15...\n8          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.3691 15...\n9          TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((100.1199 15...\n10         TH 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((101.3994 15..."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#wrangling",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#wrangling",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Wrangling",
    "text": "Wrangling\n\nMisspelling of province\nWe first want to check if there are potential differences between the province_en and ADM1_EN columns of our thai_drug and thai_sf variables respectively.\n\ncombined &lt;- bind_cols(thai_drug = sort(unique(thai_drug$province_en)), thai_sf = sort(unique(thai_sf$ADM1_EN)))\n\n# Compare the values\ncombined &lt;- combined %&gt;%\n  mutate(same_values = thai_drug == thai_sf) %&gt;% filter(same_values == FALSE)\n\ncombined\n\n# A tibble: 3 × 3\n  thai_drug thai_sf   same_values\n  &lt;chr&gt;     &lt;chr&gt;     &lt;lgl&gt;      \n1 buogkan   Bueng Kan FALSE      \n2 Loburi    Loei      FALSE      \n3 Loei      Lop Buri  FALSE      \n\n\nSince we found some mismatches in the data, let’s correct them.\n\nthai_drug &lt;- thai_drug %&gt;%\n  mutate(province_en = recode(province_en,\n                              \"buogkan\" = \"Bueng Kan\",\n                              \"Loburi\" = \"Lop Buri\"))\n\nWhen checking for anymore mismatches or mispellings\n\ncombined &lt;- bind_cols(thai_drug = sort(unique(thai_drug$province_en)), thai_sf = sort(unique(thai_sf$ADM1_EN)))\n\n\ncombined &lt;- combined %&gt;%\n  mutate(same_values = thai_drug == thai_sf) %&gt;% filter(same_values == FALSE)\n\n\ncombined\n\n# A tibble: 0 × 3\n# ℹ 3 variables: thai_drug &lt;chr&gt;, thai_sf &lt;chr&gt;, same_values &lt;lgl&gt;\n\n\nWe find that our data is now sound\n\n\nCRS\nWe also want to ensure that the CRS of our data is set correctly to WGS84 with EPSG 32647\n\nst_crs(thai_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nWe see that the EPSG value is wrong. Let us now convert it using st_transform()\n\nthai_sf &lt;- thai_sf %&gt;% st_transform(crs = 32647)\nst_crs(thai_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\n\nBoundary file\nLet’s now plot the boundary file to check for any missing values or areas\n\nthai_sf_union &lt;- st_union(thai_sf)\nplot(thai_sf_union)\n\n\n\n\n\n\n\n\n\n\nDrug abuse data\nWe lastly want to check whether our drug abuse dataset is correctly filled without missing rows\n\nthai_drug_summary &lt;- thai_drug %&gt;%\n  summarise(na_year = sum(is.na(fiscal_year)),\n            na_province = sum(is.na(province_en)),\n            na_drug_offense = sum(is.na(types_of_drug_offenses)),\n            na_cases = sum(is.na(no_cases)))\nprint(thai_drug_summary)\n\n# A tibble: 1 × 4\n  na_year na_province na_drug_offense na_cases\n    &lt;int&gt;       &lt;int&gt;           &lt;int&gt;    &lt;int&gt;\n1       0           0               0        0\n\n\n\n\nLeft Join\nWe can now join the data after ensuring the datasets are correct\n\nthai_joined &lt;- left_join(thai_sf,thai_drug, by = c(\"ADM1_EN\" = \"province_en\")) %&gt;%\n        select(1:3, 17:19,21)\n\n\n\nFiltering\nWe should now find out all the different types of offenses and filter out the ones we do not need\n\nunique(thai_joined$types_of_drug_offenses)\n\n [1] \"drug_use_cases\"                                        \n [2] \"suspects_in_drug_use_cases\"                            \n [3] \"possession_cases\"                                      \n [4] \"suspects_in_possession_cases\"                          \n [5] \"possession_with_intent_to_distribute_cases\"            \n [6] \"suspects_in_possession_with_intent_to_distribute_cases\"\n [7] \"trafficking_cases\"                                     \n [8] \"suspects_in_trafficking_cases\"                         \n [9] \"production_cases\"                                      \n[10] \"suspects_in_production_cases\"                          \n[11] \"import_cases\"                                          \n[12] \"suspects_in_import_cases\"                              \n[13] \"export_cases\"                                          \n[14] \"suspects_in_export_cases\"                              \n[15] \"conspiracy_cases\"                                      \n[16] \"suspects_in_conspiracy_cases\"                          \n\n\nSince our objective is for drug abuse, we want to remove suspects as they are unconfirmed along with conspiracy as these are only related to plans.\n\ndrug_offenses &lt;- c(\n  \"drug_use_cases\", \"possession_cases\", \"possession_with_intent_to_distribute_cases\", \"trafficking_cases\", \"production_cases\", \"import_cases\", \"export_cases\"\n)\nthai_joined &lt;- thai_joined %&gt;% filter(types_of_drug_offenses %in% drug_offenses )\n\nWe should now split up the data by years\n\ndrug_1722_list &lt;- list()\nfor (year in 2017:2022) {\n  drug_1722_list[[as.character(year)]] &lt;- thai_joined %&gt;% filter(fiscal_year == year)\n}\n\nglimpse(drug_1722_list[[\"2017\"]])\n\nRows: 539\nColumns: 7\n$ Shape_Leng             &lt;dbl&gt; 2.417227, 2.417227, 2.417227, 2.417227, 2.41722…\n$ Shape_Area             &lt;dbl&gt; 0.13133873, 0.13133873, 0.13133873, 0.13133873,…\n$ ADM1_EN                &lt;chr&gt; \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Bangkok\", \"Ba…\n$ fiscal_year            &lt;dbl&gt; 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,…\n$ types_of_drug_offenses &lt;chr&gt; \"drug_use_cases\", \"possession_cases\", \"possessi…\n$ no_cases               &lt;dbl&gt; 11871, 9224, 6374, 950, 316, 0, 2, 820, 3348, 1…\n$ geometry               &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((674339.8 15..., MU…\n\n\n\n\nSimple Visualisations\nWe can take a peak at a visualisation of the data from 2017 checking the number of cases of drug abuse\n\nqtm(drug_1722_list[[\"2017\"]], \"no_cases\")\n\nSome legend labels were too wide. These labels have been resized to 0.62, 0.58. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Global Measures of Spatial Autocorrelation",
    "text": "Global Measures of Spatial Autocorrelation\n\nCalculating Neighbours and Weights\nWe want to define neighbours using Queens contiguity along with assigning spatial weights to neighbouring polygons.\nAs our dataset is large and spans across 6 years, it would take very long to render. Thus, we will make use or parellelism to apply the expensive st_contiguity() and st_weights() functions.\n\n# Load required libraries\nlibrary(dplyr)\nlibrary(parallel)\n\n# Determine the number of cores to use\nnum_cores &lt;- detectCores() - 1  # Use all cores except one\n\n# Create a cluster\ncl &lt;- makeCluster(num_cores)\n\n# Export necessary functions and objects to the cluster\nclusterExport(cl, c(\"drug_1722_list\", \"st_contiguity\", \"st_weights\"))\n\n# Load required packages on each core\nclusterEvalQ(cl, {\n  library(sf)\n  library(dplyr)\n})\n\n# Parallelise the loop\nwm_q_list &lt;- parLapply(cl, as.character(2017:2022), function(year) {\n  wm_q &lt;- drug_1722_list[[year]] %&gt;% \n    mutate(nb = st_contiguity(., queen = TRUE),\n           wt = st_weights(nb, style = \"W\", allow_zero = TRUE),\n           .before = 1)\n  return(wm_q)\n})\n\n# Stop the cluster\nstopCluster(cl)\n\n# Name the list elements\nnames(wm_q_list) &lt;- as.character(2017:2022)\n\n\n\n\n\n\n\nImportant\n\n\n\nThe code chunk above took around 30 minutes to process on a R5 5800x3d (A fairly modern and high performing CPU). It also requires a minimum of 10GB of ram set aside just to run as each parallel proccess requires the large dataset to be duplicated.\n\n\nLet’s now save this data so we don’t need to process this again.\n\nwrite_rds(wm_q_list, \"data/rds/wm_q_list.rds\")\n\n\nwm_q_list &lt;- read_rds(\"data/rds/wm_q_list.rds\")\n\n\n\nGlobal Moran’s I Test\nWe can now perform a global Moran’s I test to assess spatial autocorrelation in our dataset. Specifically to check whether the drug use cases in our dataset are clustered, dispersed, or randomly distributed.\n\n201720182019202020212022\n\n\n\nwm_q &lt;- wm_q_list$\"2017\"\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 5.1105, p-value = 1.607e-07\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     4.781436e-02     -1.858736e-03      9.447539e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2018\"\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.8371, p-value = 6.224e-05\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.511349e-02     -1.858736e-03      9.284089e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2019\"\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.4612, p-value = 0.0002689\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.228953e-02     -1.858736e-03      9.734045e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2020\"\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 3.2211, p-value = 0.0006385\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     3.023221e-02     -1.858736e-03      9.925542e-05 \n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2021\"\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.836, p-value = 0.002284\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.0265848385     -0.0018587361      0.0001005926 \n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2022\"\nglobal_moran_test(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.0023, p-value = 0.02262\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n     0.0183256324     -0.0018587361      0.0001016153 \n\n\n\n\n\nFrom the tests run from 2017-2022, we can see that there is the presence of spatial clustering due to the small p-values. There is also a consistent positive Moran I statistic across the years. However, we can observe that it has decreased slightly over the years which might indicate a weakening in clustering. This could be due to the Covid-19 pandemic where we saw the largest drop in Moran I statistic and the distribution of drugs would have decreased along with the supply due to stricter rules on trade. We can finally look at the decrease in standard deviation values over time, which indicates less variability in the drug abuse cases across Thailand.\n\n\nGlobal Moran’s I permutation test\nWe will also look to strengthen our findings by running monte-carlo simulations for each year\n\n201720182019202020212022\n\n\n\nwm_q &lt;- wm_q_list$\"2017\"\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.047814, observed rank = 999, p-value = 0.002\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2018\"\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.035113, observed rank = 997, p-value = 0.006\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2019\"\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.03229, observed rank = 997, p-value = 0.006\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2020\"\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.030232, observed rank = 994, p-value = 0.012\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2021\"\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.026585, observed rank = 993, p-value = 0.014\nalternative hypothesis: two.sided\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2022\"\nglobal_moran_perm(wm_q$no_cases,\n           wm_q$nb,\n           wm_q$wt,\n           zero.policy = TRUE,\n           nsim = 999,\n           na.action=na.omit)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.018326, observed rank = 970, p-value = 0.06\nalternative hypothesis: two.sided\n\n\n\n\n\nThe results reinforce our original conclusion of strong spatial clustering in drug abuse cases. This can be seen from the relatively low p-values across all years. We can also see that the observed rank across all years are high. This further supports the presence of significant clustering. We can conclude that the drug abuse cases in Thailand tend to be concentrated in specific regions\nWe can now visualise these results through a histogram\n\n201720182019202020212022\n\n\n\nwm_q &lt;- wm_q_list$\"2017\"\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2017\", xlab=\"Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2018\"\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2018\", xlab=\"Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2019\"\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2019\", xlab=\"Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2020\"\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2020\", xlab=\"Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2021\"\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2021\", xlab=\"Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\nwm_q &lt;- wm_q_list$\"2022\"\ngmres &lt;-global_moran_perm(wm_q$no_cases,\n                   wm_q$nb,\n                   wm_q$wt,\n                   zero.policy = TRUE,\n                   nsim = 999,\n                   na.action=na.omit)\n\nhist(gmres$res, main=\"Histogram of Global Moran's I Monte-Carlo Simulation 2022\", xlab=\"Results\", ylab=\"Frequency\")\n\nabline(v = gmres$statistic, col = \"red\")"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#local-moran-i",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#local-moran-i",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Local Moran I",
    "text": "Local Moran I\nLocal Indicators of Spatial Association, or LISA, let us evaluate clusters between provinces. Where higher values denote that the region is more heavily influenced by its surroundings.\n\nCalculating Local Moran I\nCalculating local Moran’s I statistics and append the results to the original dataframe as new columns.\n\nlisa_list &lt;- list()\nfor (year in 2017:2022) {\n  wm_q &lt;- wm_q_list[[as.character(year)]] %&gt;%\n          mutate(local_moran = local_moran(\n            no_cases, nb, wt, nsim = 999, zero.policy=TRUE),\n                 .before = 1) %&gt;%\n          unnest(local_moran)\n  lisa_list[[as.character(year)]] &lt;- wm_q\n  \n}\n\n\n\nVisualising Local Moran I\n\n20172018\n\n\n\nlisa &lt;- lisa_list$\"2017\"\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nThe results here indicate that Bangkok specifically is a part of Thailand that has drug abuse cases that are highly correlated but with these values being not strongly correlated with its neighbouring regions. This could be due to Bangkok being a tourist hotspot along with a generally higher level of wealth comapred to other parts of Thailand. This would allow the drug trade to thrive there due to high human density along with generaly wealth.\nWe can also see the south of Thailand, specifically Nakhon Si Thammarat, where there is high spatial autocorrelation while not being correlated with its neighbours.\n\n\n\nlisa &lt;- lisa_list$\"2018\"\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nWe can see here that the regions with low or high numbers of drug abuse cases have become generally more spatially autocorrelated while the statistical significance of said clusters has decreased. This could indicate higher randomness in drug abuse cases even with spatial patterns emerging.\n\n2019\n\nlisa &lt;- lisa_list$\"2019\"\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nWe can observe further clustering of drug abuse cases in central and south Thailand with a slight reduction in randomness. There is also a new cluster beginning to form towards the north.\n\n\n2020\n\nlisa &lt;- lisa_list$\"2020\"\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nWe can see that the clusters are generally dispersing with the values in the southern region being statistically more significant. This could be due to the Covid 19 pandemic where tourism would have dropped significantly due to the travel bans. Thus, only native Thai drug abuse cases would be contained within this year.\n\n\n2021\n\nlisa &lt;- lisa_list$\"2021\"\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nWe can see here that the clustering of cases are back along with having slightly worse statistical significance. The main areas we can look at are the central, south and north of Thailand. We can probably presume the travel bans were lifted within this year or easing of Covid-19 restrictions.\n\n\n2022\n\nlisa &lt;- lisa_list$\"2022\"\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of No of cases\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can see here that there is now a general dispersion from the previous years of clusters in the central and southern regions. The statistical significance of these regions have also completely fizzled out. There is however a new cluster in the central north of Thailand."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#lisa",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#lisa",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "LISA",
    "text": "LISA\nThe local indicator of spatial association (LISA) for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation. LISA map is a categorical map showing type of outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two type of clusters namely: High-High and Low-Low clusters.\n\nHigh-Low Outliers: Provinces with a high value of drug cases, surrounded by neighbouring provinces with low values of drug cases.\nLow-High Outliers: Provinces with a low value of drug cases, surrounded by neighbouring provinces with high values of drug cases.\nHigh-High Clusters: Provinces with a high value of drug cases, surrounded by neighbouring provinces with high values of drug cases.\nLow-Low Clusters: Provinces with a low value of drug cases, surrounded by neighbouring provinces with low values of drug cases.\n\n\ncreate_lisa_map &lt;- function(year, lisa_data, lisa_sig) {\n  tm_shape(lisa_data) +\n    tm_polygons() + \n    tm_borders(alpha = 0.5) + \n    tm_shape(lisa_sig) + \n    tm_fill(\"mean\", title = \"LISA class\") +\n    tm_borders(alpha = 0.4) +\n    tm_layout(main.title = paste(\"LISA map of drug cases\", year), \n              main.title.size = 1)\n}\n\n# Create significant LISA data frames and maps\nyears &lt;- 2017:2022\nlisa_sig_list &lt;- list()\nmaps &lt;- list()\n\nfor (year in years) {\n  year_str &lt;- as.character(year)\n  \n  # Filter significant LISA results\n  lisa_sig_list[[year_str]] &lt;- lisa_list[[year_str]] %&gt;% \n    filter(p_ii_sim &lt; 0.05)\n  \n  # Create map\n  maps[[year_str]] &lt;- create_lisa_map(year, lisa_list[[year_str]], lisa_sig_list[[year_str]])\n}\n\n# Arrange all maps\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntmap_arrange(maps, ncol = 3)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\n\nHigh-Low Outliers: Interestingly this only occurs for the year 2017, 2019 and 2020. And are generally found near cold spots\nLow-High Outliers: Most of the province classified under this are situated near the central south of Thailand which is near the tourist area and also the very southern region. And for 2022 its actually in the northern eastern region.\nHigh-High Clusters: There is an absence of any high-high classification, suggest that there are no high-value province surrounded by other high-value provinces\nLow-Low Clusters: Many of the provinces classified here are actually found in the western or upper central part of Thailand which is somewhat near the tourist area of Bangkok where there are low-high outliers."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Emerging Hot Spot Analysis",
    "text": "Emerging Hot Spot Analysis\n\nCalculating the local Gi*\nEmerging hot spot Analysis (EHSA) is a technique that falls under exploratory spatial data analysis (ESDA). It combines the traditional ESDA technique of hot spot analysis using the Getis-Ord Gi* statistic with the traditional time-series Mann-Kendall test for monotonic trends.\nThe goal of EHSA is to evaluate how hot and cold spots are changing over time. It helps us answer the questions: are they becoming increasingly hotter, are they cooling down, or are they staying the same?\nIn brief, EHSA works by calculating the Gi* for each time period. The series of Gi* at each location is treated as a time-series and evaluated for a trend using the Mann-Kendall statistic. The Gi* and the Mann-Kendall are compared together to create 17 unique classifications to help better understand how the locations have changed over time.\nFirst we create a neighbor list ensuring that the self is included and then create the weights list from the new neighbors list. Let’s do this for the year 2018 only\n\nwm_idw_2018 &lt;- drug_1722_list$\"2018\" %&gt;%\n    mutate(nb = include_self(st_contiguity(geometry)),\n           wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n           .before = 1)\n\nBefore we forget let’s write the wm_idw_2018 into an rds file for faster access\n\nwrite_rds(wm_idw_2018, \"data/rds/wm_idw_2018.rds\")\n\nFollowing, we calculate the local Gi* using local_gstar_perm() on the no_cases column which creates a new data frame column called gi_star. We then unnest it using tidyr::unnest().\n\ncases_gistar_2018 &lt;- wm_idw_2018 %&gt;% \n  transmute(gi_star = local_gstar_perm(no_cases, nb, wt, nsim = 199)) %&gt;% \n  tidyr::unnest(gi_star)\n\nLastly, we classify the clusters using a combination of mutate() and case_when() which is then piped into a ggplot map. While not a perfect recreation of the GeoData map, it is very close—the differences likely due to conditional permutation (see conditional permutation vignette for more on significance calculation).\n\ncases_gistar_2018 %&gt;% \n  mutate(cluster = case_when(\n    p_folded_sim &gt; 0.05 ~ \"Not Significant\",\n    p_folded_sim &lt;= 0.05 & gi_star &lt; 0 ~ \"Low\",\n    p_folded_sim &lt;= 0.05 & gi_star &gt; 0 ~ \"High\"\n  )) |&gt; \n  ggplot(aes(fill = cluster)) +\n  geom_sf(lwd = 0.2, color = \"black\") +\n  scale_fill_manual(values = c(\"High\" = \"red\",\n                               \"Low\" = \"Blue\", \n                               \"Not Significant\" = \"white\")) +\n  theme_void()"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "href": "Take-home_EX/Take-home_Ex02/Take-home_Ex02.html#conclusion",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "Conclusion",
    "text": "Conclusion\nWe can see from the data derived that while there have been clusters of drug abuse in Thailand over the years ranging from 2017-2022, the Covid-19 pandemic seems to have greatly affected the clustering of these cases. This could be due to traffickers having to move around to avoid arrest from the authorities."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications. You will find my work done for this course."
  },
  {
    "objectID": "index.html#hands-on-exercises",
    "href": "index.html#hands-on-exercises",
    "title": "IS415-GAA",
    "section": "Hands-on Exercises",
    "text": "Hands-on Exercises\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 1\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2024\n\n\nFan Syong Yue\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 2: Thematic Mapping and GeoVisualisation\n\n\n\n\n\n\n\n\n\n\n\nAug 24, 2024\n\n\nFan Syong Yue\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\n\n\n\n\n\nAug 27, 2024\n\n\nFan Syong Yue\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5: Spatial Weights and Applications\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2024\n\n\nFan Syong Yue\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6: Measures of Spatial Autocorrelation\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2024\n\n\nFan Syong Yue\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques\n\n\n\n\n\n\n\n\n\n\n\nOct 13, 2024\n\n\nFan Syong Yue\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5",
    "section": "",
    "text": "We will be using 2 data sets for this exercise\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#joining-the-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#joining-the-data",
    "title": "In-class Exercise 5",
    "section": "Joining the Data",
    "text": "Joining the Data\nWe want to combine the data to update the hunan SpatialPolygonsDataFrame with the attribute fields of hunan2012\n\nhunan_sf &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\nWe want to save the data that we have selected\n\nwrite_rds(hunan_sf, \"data/rds/hunan_sf.rds\")\n\nWe can now check and reimport the data into hunan_sf\n\nhunan_sf &lt;- read_rds(\"data/rds/hunan_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#converting-to-spatialpolygondataframe",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#converting-to-spatialpolygondataframe",
    "title": "In-class Exercise 5",
    "section": "Converting to SpatialPolygonDataFrame",
    "text": "Converting to SpatialPolygonDataFrame\n\nhunan_sp &lt;- as_Spatial(hunan_sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#adaptive-bandwith",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#adaptive-bandwith",
    "title": "In-class Exercise 5",
    "section": "Adaptive bandwith",
    "text": "Adaptive bandwith\n\nCross Validation\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\n\nAIC\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = TRUE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\n\nComputing\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               adaptive = TRUE,\n               kernel = \"bisquare\",\n               longlat = T)\n\n\n\nPreparing output data\nWe want to extract the SDF data table from the gwss object and convert it into a data.frame by using as.data.frame()\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nWe now want to append the derived data onto the hunan_sf data.frame. We will use cbind() to achieve this\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\n\nVisualisation\nWe want to display the geographically weighted mean\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geograhpically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#fixed-bandwith",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#fixed-bandwith",
    "title": "In-class Exercise 5",
    "section": "Fixed Bandwith",
    "text": "Fixed Bandwith\n\nCross Validation\n\nbw_fixed_CV &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\n\nAIC\n\nbw_fixed_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = \"AIC\",\n                 adaptive = FALSE,\n                 kernel = \"bisquare\",\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/In-class_Ex04/data/rawdata/Kepulauan_Bangka_Belitung.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "We want to use tidyverse and sf packages\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data",
    "title": "In-class Exercise 2",
    "section": "Importing the data",
    "text": "Importing the data\nWe want to first import the shp shapefile\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\",\n                        layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/In-class_Ex/In-class_Ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nSince the original downladed KML file errors out, let’s create one using the SHP file\n\nst_write(mpsz14_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nWe now want to import the kml file\n\nmpsz14_kml &lt;- st_read(\"data/MP14_SUBZONE_WEB_PL.kml\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/In-class_Ex/In-class_Ex02/data/MP14_SUBZONE_WEB_PL.kml' \n  using driver `KML'\nSimple feature collection with 323 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data-1",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data-1",
    "title": "In-class Exercise 2",
    "section": "Importing the data",
    "text": "Importing the data\nWe want to first import the shp shapefile\n\nmpsz19_shp &lt;- st_read(dsn = \"data/\",\n        layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/In-class_Ex/In-class_Ex02/data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nWe now want to import the kml file\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/In-class_Ex/In-class_Ex02/data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-processing",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#data-processing",
    "title": "In-class Exercise 2",
    "section": "Data processing",
    "text": "Data processing\nWe now want to process and split the data\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+rowSums(.[15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\nNow we can join popdata2023 and mpsz19_shp_3414\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper))\n\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp_3414, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\nglimpse(mpsz_pop2023)\n\nRows: 332\nColumns: 13\n$ SUBZONE_N        &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", …\n$ SUBZONE_C        &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MP…\n$ PLN_AREA_N       &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WE…\n$ PLN_AREA_C       &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\",…\n$ REGION_N         &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\",…\n$ REGION_C         &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\",…\n$ PA               &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WE…\n$ YOUNG            &lt;dbl&gt; 0, 1050, 1050, 0, 30, 0, 0, 0, 0, 690, 0, 0, 0, 1240,…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 0, 2290, 2380, 0, 140, 0, 0, 0, 0, 1470, 0, 0, 0, 280…\n$ AGED             &lt;dbl&gt; 0, 370, 300, 0, 10, 0, 0, 0, 0, 230, 0, 0, 0, 590, 36…\n$ TOTAL            &lt;dbl&gt; 0, 3710, 3730, 0, 180, 0, 0, 0, 0, 2390, 0, 0, 0, 463…\n$ DEPENDENCY       &lt;dbl&gt; NaN, 0.6200873, 0.5672269, NaN, 0.2857143, NaN, NaN, …\n$ geometry         &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOL…\n\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp_3414,\n                          by = c(\"SZ\" = \"SUBZONE_N\"))\nglimpse(pop2023_mpsz)\n\nRows: 332\nColumns: 13\n$ PA               &lt;chr&gt; \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO…\n$ SZ               &lt;chr&gt; \"ANG MO KIO TOWN CENTRE\", \"CHENG SAN\", \"CHONG BOON\", …\n$ YOUNG            &lt;dbl&gt; 1240, 5150, 4620, 4320, 1840, 3810, 1870, 3750, 0, 10…\n$ `ECONOMY ACTIVE` &lt;dbl&gt; 2830, 15600, 14120, 12400, 3670, 9600, 4320, 11090, 0…\n$ AGED             &lt;dbl&gt; 890, 6580, 7060, 5640, 1420, 4320, 1790, 5390, 0, 880…\n$ TOTAL            &lt;dbl&gt; 4960, 27330, 25800, 22360, 6930, 17730, 7980, 20230, …\n$ DEPENDENCY       &lt;dbl&gt; 0.7526502, 0.7519231, 0.8271955, 0.8032258, 0.8882834…\n$ SUBZONE_C        &lt;chr&gt; \"AMSZ01\", \"AMSZ02\", \"AMSZ03\", \"AMSZ06\", \"AMSZ07\", \"AM…\n$ PLN_AREA_N       &lt;chr&gt; \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO…\n$ PLN_AREA_C       &lt;chr&gt; \"AM\", \"AM\", \"AM\", \"AM\", \"AM\", \"AM\", \"AM\", \"AM\", \"AM\",…\n$ REGION_N         &lt;chr&gt; \"NORTH-EAST REGION\", \"NORTH-EAST REGION\", \"NORTH-EAST…\n$ REGION_C         &lt;chr&gt; \"NER\", \"NER\", \"NER\", \"NER\", \"NER\", \"NER\", \"NER\", \"NER…\n$ geometry         &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((29692.8 389..., MULTIPOL…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this exercise, we want to learn how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#packages",
    "title": "Hands-on Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Packages",
    "text": "Packages\nWe will be using the following packages:\n\nsf\nspdep\ntmap\nClustGeo\nggpubr\ncluster\nfactoextra\nNbClust\nheatmaply\ncorrplot\npsych\ntidyverse\nGGally\n\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#data",
    "title": "Hands-on Exercise 7: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "Data",
    "text": "Data\nWe will be using 2 datasets in this exercise\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are download from Myanmar Information Management Unit (MIMU)\n\nImporting\nWe first want to import the geospatial data\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nLet’s now use glimpse() to look at the data fields of shan_sf\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\nNow, let’s import the aspatial population and housing data\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nWe can see that there are 11 fields and 55 observations in the data frame\n\n\nWrangling\nWe now want to derive some variables from the ict variable and store it\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet’s now take a look at the derived variable\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nWe can see the fields we have added are included"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "We will be using 2 data sets for this exercise\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nWe will be using the following packages:\n\nsf\nspdep\ntmap\ntidyverse\nknitr\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\n\n\nhunan  &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nWe want to combine the data to update the hunan SpatialPolygonsDataFrame with the attribute fields of hunan2012\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\n\nWe first want to visualise the data using the basemap and choropleth map distribution of GDPPC 2012 using qtm() from tmap\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nTo achieve this, we will use the poly2nb() function from spdep to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. A “queen” argument can be passed in that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nWe will now compute the Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe data indicates that Hunan consists of 88 area units. The most connected unit has 11 neighbouring areas, while two units each have only one neighboring area.\nwm_q can now be used to list all neighbouring polygons. Let’s look at the first polygon in the object.\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nTo view the county name of polygon 1, we can use the following code\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nWe can also reveal the name of the five neighbouring polygons\n\nhunan$County[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can now retrieve the GDPPC of the five counties\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can also display the complete weight matrix with the following code\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nWe will now compute the Rook contiguity weight matrix\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe data indicates that Hunan consists of 88 area units. The most connected unit has 10 neighbouring areas, while two units each have only one neighboring area.\n\n\n\nTo create a connectivity graph, we need points to represent each polygon. The most common way to get these points is by calculating polygon centroids. We’ll do this using the sf package before moving on to graph creation.\nTo extract latitude and longitude from the centroids, we’ll use the st_centroid() function on the geometry column of the us.bound object. Since we need the coordinates in a separate data frame, we’ll use a mapping function from the purrr package. Specifically, we’ll use map_dbl() to apply st_centroid() and extract the longitude (the first value) using [[1]].\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nFor latitude, we access the 2nd value of each centroid\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWe now combine the coordinates into the same object and view them\n\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo achieve this, we will use dnearneigh() from the spdep package.\nThis function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nWe first need to determine the upper limit for distance band by using the following steps:\n\nGetting a matrix of the indices of points from the set of the k-nearest neighbors using dnearneigh()\nConvert the matrix into a neighbors list of nb class using knn2nb()\nUse nbdists() to get the length of neighbor relationship edges. If projected, return coordinate pairs, else km,\nRemove the list structure using unlist()\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\n\nWarning in knn2nb(knearneigh(coords)): neighbour object has 25 sub-graphs\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nWe can now use dnearneigh() to compute the distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThis shows us that each of the 88 counties are connected to 3.68 other counties on average\nWe can also view the weight matrix directly\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWe could alternatively use the table() and card() functions of spdep to display this structure\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\nWith this, we can see that there are no isolated counties and the graph is completely connected.\n\n\nWe can now plot the distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nWe could also plot them next to each other instead of on the same graph\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k = 6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe can also display the content of this matrix\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nThis shows that each county has 6 neightbours.\n\n\nWe now want to plot the distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nIDW is a type of deterministic interpolation method used to estimate values at unsampled locations based on the values of nearby sampled points.\nWe will first compute the distances between areas by using nbdists() of spdep\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\n\n\nTo assign weights to each neighbouring polygon, we’ll use equal weights with style = \"W\". This means each neighbouring polygon is assigned a weight of ( 1/(# of neighbours) ), and we sum the weighted values.\nWhile this method is intuitive, it has a drawback: polygons at the edges of the study area have fewer neighbours, which can lead to over- or underestimation of spatial autocorrelation. For simplicity, we’ll use style = \"W\", but other robust options, such as style = \"B\", are available.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbours. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbours type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbour is assigned a 0.125 of the total weight. This means that when R computes the average neighbouring income values, each neighbour’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nWe can now view the weights\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338 \n\n\n\n\n\nWe can create four different spatial lagged variables\n\nspatial lag with row-standardized weights\nspatial lag as a sum of neighbouring values\nspatial window average\nspatial window sum\n\n\n\nWe can compute the average neighbor GDPPC value for each polygon\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lagged GDPPC values onto the hunan sf data frame\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nWe can now plot both the GDPPC and spatial lag GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighbouring values by assigning binary weights. This requires us to go back to our neighbours list, then apply a function that will assign binary weights, then we use glist = in the nb2listw() function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbour. This is done with lapply(), which we have been using to manipulate the neighbours structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nWe can now view the result\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nWe will append the lag_sum GDPPC field into hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nWe can now plot both the GDPPC and Spatial Lag Sum GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardised weights and includes the diagonal element.\nWe can use include.self() from spdep to add the diagonal element to the neighbour list\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nLet’s look at neighbour list of area [1]\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n[1] now has 6 neighbors from 5\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nWe will now convert the lag variable listw object into a data.frame by using as.data.frame()\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNow we append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_avg_gdppc maps next to each other for quick comparison\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardised weights\nWe can use include.self() from spdep to add the diagonal element to the neighbour list\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nWe now assign binary weights to the neighbour structure that includes the diagonal element\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n[1] now has 6 neighbors from 5\nWe use nb2listw() and glist() to explicitly assign weight values\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nNow compute the lag variable with lag.listw()\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nWe will now convert the lag variable listw object into a data.frame by using as.data.frame()\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNow we append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "We will be using 2 data sets for this exercise\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#packages",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "We will be using the following packages:\n\nsf\nspdep\ntmap\ntidyverse\nknitr\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#data-1",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "hunan  &lt;- st_read(dsn = \"data/geospatial\", layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nWe want to combine the data to update the hunan SpatialPolygonsDataFrame with the attribute fields of hunan2012\n\nhunan &lt;- left_join(hunan,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-regional-development-indicator",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "We first want to visualise the data using the basemap and choropleth map distribution of GDPPC 2012 using qtm() from tmap\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.5)\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\ntmap_arrange(basemap, gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "To achieve this, we will use the poly2nb() function from spdep to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. A “queen” argument can be passed in that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n\nWe will now compute the Queen contiguity weight matrix\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe data indicates that Hunan consists of 88 area units. The most connected unit has 11 neighbouring areas, while two units each have only one neighboring area.\nwm_q can now be used to list all neighbouring polygons. Let’s look at the first polygon in the object.\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nTo view the county name of polygon 1, we can use the following code\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nWe can also reveal the name of the five neighbouring polygons\n\nhunan$County[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can now retrieve the GDPPC of the five counties\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can also display the complete weight matrix with the following code\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"snap\")= num 9e-08\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\n\n\n\nWe will now compute the Rook contiguity weight matrix\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe data indicates that Hunan consists of 88 area units. The most connected unit has 10 neighbouring areas, while two units each have only one neighboring area.\n\n\n\nTo create a connectivity graph, we need points to represent each polygon. The most common way to get these points is by calculating polygon centroids. We’ll do this using the sf package before moving on to graph creation.\nTo extract latitude and longitude from the centroids, we’ll use the st_centroid() function on the geometry column of the us.bound object. Since we need the coordinates in a separate data frame, we’ll use a mapping function from the purrr package. Specifically, we’ll use map_dbl() to apply st_centroid() and extract the longitude (the first value) using [[1]].\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nFor latitude, we access the 2nd value of each centroid\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nWe now combine the coordinates into the same object and view them\n\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#computing-distance-based-neighbours",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "To achieve this, we will use dnearneigh() from the spdep package.\nThis function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n\nWe first need to determine the upper limit for distance band by using the following steps:\n\nGetting a matrix of the indices of points from the set of the k-nearest neighbors using dnearneigh()\nConvert the matrix into a neighbors list of nb class using knn2nb()\nUse nbdists() to get the length of neighbor relationship edges. If projected, return coordinate pairs, else km,\nRemove the list structure using unlist()\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\n\nWarning in knn2nb(knearneigh(coords)): neighbour object has 25 sub-graphs\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n\nWe can now use dnearneigh() to compute the distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThis shows us that each of the 88 counties are connected to 3.68 other counties on average\nWe can also view the weight matrix directly\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWe could alternatively use the table() and card() functions of spdep to display this structure\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\nWith this, we can see that there are no isolated counties and the graph is completely connected.\n\n\nWe can now plot the distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nWe could also plot them next to each other instead of on the same graph\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k = 6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nWe can also display the content of this matrix\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"ncomp\")=List of 2\n  ..$ nc     : int 1\n  ..$ comp.id: int [1:88] 1 1 1 1 1 1 1 1 1 1 ...\n\n\nThis shows that each county has 6 neightbours.\n\n\nWe now want to plot the distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#weights-based-on-inverse-distance-weighting",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#weights-based-on-inverse-distance-weighting",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "IDW is a type of deterministic interpolation method used to estimate values at unsampled locations based on the values of nearby sampled points.\nWe will first compute the distances between areas by using nbdists() of spdep\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "To assign weights to each neighbouring polygon, we’ll use equal weights with style = \"W\". This means each neighbouring polygon is assigned a weight of ( 1/(# of neighbours) ), and we sum the weighted values.\nWhile this method is intuitive, it has a drawback: polygons at the edges of the study area have fewer neighbours, which can lead to over- or underestimation of spatial autocorrelation. For simplicity, we’ll use style = \"W\", but other robust options, such as style = \"B\", are available.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbours. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbours type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbour is assigned a 0.125 of the total weight. This means that when R computes the average neighbouring income values, each neighbour’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nWe can now view the weights\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 5: Spatial Weights and Applications",
    "section": "",
    "text": "We can create four different spatial lagged variables\n\nspatial lag with row-standardized weights\nspatial lag as a sum of neighbouring values\nspatial window average\nspatial window sum\n\n\n\nWe can compute the average neighbor GDPPC value for each polygon\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nWe can append the spatially lagged GDPPC values onto the hunan sf data frame\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nWe can now plot both the GDPPC and spatial lag GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWe can calculate spatial lag as a sum of neighbouring values by assigning binary weights. This requires us to go back to our neighbours list, then apply a function that will assign binary weights, then we use glist = in the nb2listw() function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbour. This is done with lapply(), which we have been using to manipulate the neighbours structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nWe can now view the result\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nWe will append the lag_sum GDPPC field into hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nWe can now plot both the GDPPC and Spatial Lag Sum GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window average uses row-standardised weights and includes the diagonal element.\nWe can use include.self() from spdep to add the diagonal element to the neighbour list\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nLet’s look at neighbour list of area [1]\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\n[1] now has 6 neighbors from 5\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nWe will now convert the lag variable listw object into a data.frame by using as.data.frame()\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNow we append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_avg_gdppc maps next to each other for quick comparison\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nThe spatial window sum is the counter part of the window average, but without using row-standardised weights\nWe can use include.self() from spdep to add the diagonal element to the neighbour list\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nWe now assign binary weights to the neighbour structure that includes the diagonal element\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\n[1] now has 6 neighbors from 5\nWe use nb2listw() and glist() to explicitly assign weight values\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nNow compute the lag variable with lag.listw()\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nWe will now convert the lag variable listw object into a data.frame by using as.data.frame()\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNow we append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "",
    "text": "Thematic mapping utilises map symbols to highlight geographic features that are not naturally visible. Examples include population, temperature and crime rate.\nGeovisualisation, however, uses graphics to make a place, phenomenon, or process visible, tapping into our powerful spatial cognition and eye-brain vision system.\nWe will learn more about how to plot functional and truthful choropleth maps using the tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#packages",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Packages",
    "text": "Packages\nWe will be using the following packages aside from tmap\n\ntidyverse\n\nreadr - importing delimited text files\ntidyr - tidying data\ndplyr - wrangling data\n\nsf - handling geospatial data\n\n\npacman::p_load(sf,tmap,tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Data",
    "text": "Data\nThe following datasets will be used\n\nMaster Plan 2014 Subzone Boundary Data\nSingapore Residents by Planning Are / Subzone, Age Group, Sex, and Dwelling\n\nWe first use st_read() to import the geospatial data into a variable called mpsz\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/Hands-on_Ex/Hands-on_Ex02/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nWe now import the aspatial data in an R dataframe popdata\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Data Preparation",
    "text": "Data Preparation\nWe first want to prepare a data table with year 2020 values with the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: Age groups 0-4 until 20-24\nECONOMY ACTIVE: Age groups 25-29 until 60-64\nAGED: Age group 65+\nTOTAL: All age groups\nDEPENDENCY: ratio between the YOUNG and AGED ages groups against the ECONOMY ACTIVE age group\n\n\nData Wrangling\nWe will now use pivot_wider() from tidyr along with mutate(), filter(), group_by() and select() from dplyr\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG, values_from = POP) %&gt;%\n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+rowSums(.[15])) %&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\n\n\nJoining attribute and geospatial data\nAs the values in the PA and SZ fields are made up of upper- and lowercase characters, we will need to convert them all into uppercase to be used when joining with SUBZONE_N and PLN_AREA_N.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nWe can now properly join the data using the standardised names using left_join()\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020, by = c(\"SUBZONE_N\" = \"SZ\"))\n\nWe want to now save this into a file\n\nwrite_rds(mpsz_pop2020, \"data/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-choropleth-map-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-choropleth-map-using-qtm",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Plotting a choropleth map using qtm()",
    "text": "Plotting a choropleth map using qtm()\nUsing qtm() from the tmap package us the easiest and quickest way to draw a choropleth map. It provides a good and concise default vistualisation that covers a large number of cases.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nFrom the code above, we set tmap_mode(\"plot\") which provides us with a static map. If we required an interactive mode, “view” in replace of “plot” within tmap_mode() would be required. We should also note of the fill argument which selects which attribute we are mapping.\nWhile useful for quickly producing a choropleth map, qtm() is not without disadvantages. Aesthetics of individual layers are hard to control."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-by-using-tmaps-elements",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Creating a choropleth map by using tmap’s elements",
    "text": "Creating a choropleth map by using tmap’s elements\nIf we wanted to draw a high quality cartographic choropleth map, we want to use tmap’s drawing elements.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"Dependency Ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type = \"8star\", size = 2) +\n  tm_scale_bar() + tm_grid(alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nNow, let us break down the individual subfunctions used to make the above map\n\nBase map\nWe use tm_shape() to define our input data and tm_polygons() to draw out the map.\n\ntm_shape(mpsz_pop2020) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\nDraw a Choropleth Map with tm_polygons()\nWe now want to specify the variable we want to use for drawing the choropleth map\n\ntm_shape(mpsz_pop2020) + tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nWe should note that the default binning used to draw the choropleth map is called “pretty”, the default colour scheme used is YlOrRd from ColorBrewer and by default, missing values are shaded in grey.\nFurthermore, tm_shape() is in fact a wrapper function of tm_fill() and tm_border(). tm_fill() shades the polygons using the default colour scheme while tm_border() adds the borders of the shapefile onto the choropleth map.\n\n\nDrawing choropleth maps using tm_fill() and tm_border()\nLet’s first see how tm_fill works when used alone\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nNotice how the planning subzones are shared according to the respective dependency values? We can solve this using tm_borders()\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\") + tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\n\n\nThe alpha argument is used to define transparency using a value between 0 (transparent) and 1 (opaque). By default, the alpha value of the col is used (normally 1).\nBesides alpha, there are three other arguments for tm_borders():\n\ncol -&gt; border color,\nlwd -&gt; borderline width, default 1,\nlty -&gt; borderline type, default “solid’ ."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-using-tmap",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Data Classification using tmap",
    "text": "Data Classification using tmap\ntmap provides us with ten classification methods: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks. These can be specified in tm_fill() or tm_polygons()\n\nKmeans example with 5 classes\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", n = 5, style = \"kmeans\") + tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nsd example with 5 classes\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", n = 5, style = \"sd\") + tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-maps-and-custom-breaks",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#choropleth-maps-and-custom-breaks",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Choropleth Maps and Custom breaks",
    "text": "Choropleth Maps and Custom breaks\nWith built-in styles, category breaks are computed internally. To override defaults, we can set breakpoints using the breaks argument in tm_fill(). We should also not that tmap breaks have a maximum and minimum. Thus, to retrieve n categories, n+1 elements must be specified in the breaks argument in increasing order.\nBefore we explore more on this, let’s take a look at some statistics of the DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nUsing the above results as reference, we set the breakpoints at .6, .7, .8, and .9. With the addition of the min and max breakpoints, the breaks vector is c(0, 0.6, 0.7, 0.8, 0.9, 1).\n\ntm_shape(mpsz_pop2020) + tm_fill(\"DEPENDENCY\", breaks = c(0, 0.50, 0.60, 0.70, 0.80, 1.00, 19)) + tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Colour Scheme",
    "text": "Colour Scheme\ntmap supports custom colour ramps defined by the user, or from prebuilt sets from the RColorBrewer package\nWe can try this out using the Blues colour palette by setting the palette argument in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nWe can also reverse the colour shading by adding a - prefix\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layout",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layout",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Map Layout",
    "text": "Map Layout\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios.\n\nMap Legend\nWithin tmap there are several options to modify a legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"jenks\",\n          palette = \"Blues\",\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMap Style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nLet’s first try out the “classic” style\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\nCompass, scale bar, and grid lines can also be added using tmap.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby Planning Subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.outside.size = 0.2,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\",\n             size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1,\n          alpha = 0.2) +\n  tm_credits(\"sajdad\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset styling, we can use tmap_style()\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\""
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#small-multiple-maps-a.k.a-facet-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#small-multiple-maps-a.k.a-facet-maps",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Small Multiple Maps A.K.A Facet Maps",
    "text": "Small Multiple Maps A.K.A Facet Maps\nThese maps are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nThere are 3 ways using tmap that we can plot these maps:\n\nassigning multiple values to at least one of the aesthetic arguments\ndefining a group-by variable in tm_facets()\ncreating multiple stand-alone maps with tmap_arrange()\n\n\nUsing multiple values\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(c(\"DEPENDENCY\", \"AGED\"),\n              style = c(\"equal\", \"quantile\"),\n              palette = list(\"Blues\", \"Greens\")) +\n  tm_layout(legend.position =  c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nGroup-by variable in in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette =  \"Blues\",\n          thres.poly = 0) +\n  tm_facets(by=\"REGION_N\",\n            free.coords = TRUE,\n            drop.units = TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"),\n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nCreating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) + tm_polygons (\"YOUNG\", style = \"quantile\", palette = \"Blues\")\nagedmap &lt;- tm_shape(mpsz_pop2020) + tm_polygons (\"AGED\", style = \"quantile\", palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#selection-criteria",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#selection-criteria",
    "title": "Hands-on Exercise 2: Thematic Mapping and GeoVisualisation",
    "section": "Selection Criteria",
    "text": "Selection Criteria\nInstead of creating a facet map, the selection function can be used to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.outside.size = 0.2,\n            legend.outside.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#converting-our-preschool-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#converting-our-preschool-data",
    "title": "Hands-on Exercise 1",
    "section": "Converting our Preschool Data",
    "text": "Converting our Preschool Data\nWe want to first check the coordinate system of our preschool data\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nWe can see that it uses the WGS84 system. We want to project this data into the syv21 system that our mpsz3414 variable uses.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nWe can now check if it is using the new system\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-our-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-our-data",
    "title": "Hands-on Exercise 1",
    "section": "Importing our data",
    "text": "Importing our data\nWe first want to import our aspatial listing data from AirBNB\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (6): name, host_name, neighbourhood_group, neighbourhood, room_type, l...\ndbl  (11): id, host_id, latitude, longitude, price, minimum_nights, number_o...\ndate  (1): last_review\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can now view the data using list()\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\nWe assume the data uses the wgs84 Geographic Coordinate System"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-frame-for-our-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#data-frame-for-our-aspatial-data",
    "title": "Hands-on Exercise 1",
    "section": "Data frame for our aspatial data",
    "text": "Data frame for our aspatial data\nWe now want to convert the listing data into the svy21 system that we have previously used.\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nAnd when viewing the data now\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nWe can see that geometry has been added while longitude and latitude have been dropped"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1",
    "section": "Buffering",
    "text": "Buffering\n\nScenario\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\n\n\nSolution\nWe first want to use st_buffer() and compute 5-meter buffers around paths from our cycling data\n\nbuffer_cycling &lt;- st_buffer(cyclingpath,\n                              dist=5, nQuadSegs = 30)\n\nWe then want to calculate the area of the buffers\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nWe can then use sum() to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1",
    "section": "Point-in-polygon count",
    "text": "Point-in-polygon count\n\nScenario\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone. ### Solution We first want to find pre-schools located in each planning subzone using st_intersects() followed by length() to calculate the number of pre-schools within each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nWe can then check the summarised statistics of the PreSch Count field using summary()\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nWe can then list the planning subzone with the most number of pre-schools using top_n()\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\n\n\nScenario\nWe now want to calculate the density of pre-school by planning subzone ### Solution We can use st_area() to derive the area of each planning subzone\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nWe can now use mutate() to compute the density\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nWe can now view a summary of the pre-school density data that we have derived.\n\nsummary(mpsz3414$`PreSch Density`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   5.154   6.449  10.908  35.602"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can represent events such as crime, traffic accident and disease onset, or business services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\nWe will be using spatstat on this exercise to discover the spatial point processes of childecare centres in Singapore. Through this, we want to explore and answer the following questions:\n\nAre childcare centers in Singapore randomly distributed throughout the country?\nIf not, where are the locations with a higher concentration of childcare centers?\n\n\n\nWe will be using the following packages:\n\nsf\nspatstat\nraster\nmaptools\ntmap\ntidyverse\n\nAs maptools was removed from the CRAN repository, we can only install it through an archived link.\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nInstalling package into 'C:/Users/maste/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'maptools'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\maste\\AppData\\Local\\R\\win-library\\4.4\\00LOCK\\maptools\\libs\\x64\\maptools.dll\nto\nC:\\Users\\maste\\AppData\\Local\\R\\win-library\\4.4\\maptools\\libs\\x64\\maptools.dll:\nPermission denied\n\n\nWarning: restored 'maptools'\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\maste\\AppData\\Local\\Temp\\RtmpyGhUDZ\\downloaded_packages\n\n\nWe can now load the modules required\n\npacman::p_load(tmap, sf, raster, spatstat, maptools, sp, tidyverse)\n\n\n\n\nTo answer these questions, we will be using the following datasets:\n\nMaster Plan 2014 Subzone Boundary Data\nChildcare Services (GeoJSON)\nCostalOutline from SLA\n\nWe first use st_read() to import all our into variables mpsz_sf,childcare_sf, sg_sf\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform( crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nWe want all the data to be using the same projection system, thus, we have transformed our the childcare data to use SVY21.\n\n\n\n\n\nNow that we have all the data prepared, let’s plot a simple graph using them.\n\ntm_shape(sg_sf) + tm_polygons() + tm_shape(mpsz_sf) +\n  tm_polygons() + tm_shape(childcare_sf) + tm_dots()\n\n\n\n\n\n\n\n\nFor an interactive pin map, we can use the following code\n\n#tmap_mode('view')\n#tm_shape(childcare_sf) + tm_dots()\n#tmap_mode('plot')\n\n\n\n\nWe first want to convert our data to sp’s Spatial* class using sf as_Spatial\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nWe can then check the conversion\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\nAs we are unable to convert directly into ppp, we should first convert into the generic sp format\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nWe can then view the values\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\n\n\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nWe can now plot childcare_ppp and examine the difference\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nFrom the above summary, we can see that there are duplicated points. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nTo confirm the presence of duplicates, we can run the following code\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo view which points are duplicated we can use the multiplicity() function\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nWe only want to look at locations with &gt; 1 points. We can sum the total to find out how many points have duplicates.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nWith this, we know that there are 128 duplicated points. We can also view these points through this code chunk.\n\n#tmap_mode('view')\n#tm_shape(childcare) + \n  #tm_dots(alpha = 0.3, size = 0.05)\n#tmap_mode('plot')\n\nThere are generally 3 ways to resolve the issue with duplicated points\n\nDeleting the duplicates. This however has the issue of deleting useful points\nUsing Jittering to shift duplicated points so that they do not occupy the same space\nAttaching the duplicates to the patterns as “marks”. We would then need analytical techniques that take into account those “marks”\n\nWe will be using the Jittering approach\n\nchildcare_ppp &lt;- rjitter(childcare_ppp,\n                         retry = TRUE,\n                         nsimm = 1,\n                         drop = TRUE)\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\n\n\n\nDue to the importance of confining the analysis with a geographical area like the Singapore boundary while analysing spatial point patters, we can use an owin object from the spatstat package\n\nsg_owin &lt;- as.owin(sg_sf)\n\nWe can then plot the sg_owin variable\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nWe should also view the summary\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nAs mentioned previously, we want to confine out analysis only to Singapore. To do that, let’s combine childcare_ppp with sg_owin\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nAnd view the new plotted data\n\nplot(childcareSG_ppp)\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will now explore how to perform 1st Order Spatial Point Pattern Analysis through the spatstat package. We will be focusing on 2 aspects of this.\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics\n\n\n\n\n\nThe density() function from spatstat computes a kernal density for a given set of point events. We can use diggle() to automatically help us select a bandwith for computing kernel density\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nWith the output range from 0 to 0.000035 which is way too small to comprehend due to svy21 using meter as its default unit of measurement, we will need to rescale the values. To do this, we first need to retrieve the bandwith used\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nWe want to rescale our default unit of measurement to use km instead of m\n\nchildcareSG_ppp_km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\nkde_childcareSG_bw &lt;- density(childcareSG_ppp_km, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nNow we have an output with a legend that is easy to read.\n\n\n\n\nThere are 3 other functions from spatstat that can be used aside from diggle()\n\nbw.CvL()\nbw.scott()\nbw.ppl()\n\n\n\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.322776 \n\n\n\nkde_childcareSG_bw_CvL &lt;- density(childcareSG_ppp_km, sigma =  bw.CvL, edge = TRUE, kernel = \"gaussian\")\n\n\n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.224962 1.451070 \n\n\n\nkde_childcareSG_bw_scott &lt;- density(childcareSG_ppp_km, sigma =  bw.scott, edge = TRUE, kernel = \"gaussian\")\n\n\n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n    sigma \n0.3469986 \n\n\n\nkde_childcareSG_bw_ppl &lt;- density(childcareSG_ppp_km, sigma =  bw.ppl, edge = TRUE, kernel = \"gaussian\")\n\nNow we can compare with diggle()\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(kde_childcareSG_bw, main = \"bw.diggle\")\nplot(kde_childcareSG_bw_CvL, main = \"bw.CvL\")\nplot(kde_childcareSG_bw_scott, main = \"bw.scott\")\nplot(kde_childcareSG_bw_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. However, there are 3 other options\n\nEpanechnikov\nQuartic\nDics\n\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"gaussian\"), main = \"Gaussian\")\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"epanechnikov\"), main = \"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"quartic\"), main = \"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"disc\"), main = \"Disc\")\n\nWarning in density.ppp(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince we want to use a bandwith of 600 meters, we will use a sigma value of 0.6 as childcare_ppp.km uses kilometers.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp_km, sigma = 0.6, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nAs the fixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural, we can use adaptive bandwith to alleviate this.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp_km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can now compare both of them directly\n\npar(mfrow = c(1,2))\npar(mar = c(3,2,2,1))\nplot(kde_childcareSG_600, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nWe do this to make it suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\nWe can further convert this into a raster layer\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.28627e-15, 28.87893  (min, max)\n\n\nAs the crs now reads NA, we want to convert it back to using EPSG3414\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.28627e-15, 28.87893  (min, max)\n\n\n\n\n\n\nWe can now use the raster layer and display it in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\", palette=\"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nWe want to compare the KDE of Punggol, Tampines, Choa Chu Kang and Jurong West planning areas.\n\n\nWe first want to extract the areas that we are interested in\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nWe can plot the areas to check\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nWe now want to convert them into owin objects\n\npg_owin &lt;- as.owin(pg)\ntm_owin &lt;- as.owin(tm)\nck_owin &lt;- as.owin(ck)\njw_owin &lt;- as.owin(jw)\n\nWe also want to extract out the childcare centre points within each of the areas\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nRescale from m to km:\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nOverlay the childcare centres over the area\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\nWe now want to derive the bandwith using diggle()\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\nWe can also use a fixed bandwith of 0.25km\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n\nWe want to perform the Clark-Evans test of aggregation:\n\nH0: Random distribution of childcare centres\nH1: Non-Random distribution of childcare centres\n\n\nclarkevans.test(childcareSG_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.56425, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe R value from the above result indicates clustering, and as p &lt; 0.05, H0 can be rejected.\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=sg_owin,\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79113, p-value = 8.174e-05\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe R value from the above result indicates clustering, and as p &lt; 0.05, H0 can be rejected.\n\n\n\n\nclarkevans.test(childcare_pg_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.89384, p-value = 0.05635\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p &lt; 0.05, H0 can be rejected.\n\n\n\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.9373, p-value = 0.1744\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p &gt; 0.05, H0 cannot be rejected.\n\n\n\n\nclarkevans.test(childcare_jw_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_jw_ppp\nR = 0.89493, p-value = 0.02968\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p &lt; 0.05, H0 can be rejected."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#packages",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "We will be using the following packages:\n\nsf\nspatstat\nraster\nmaptools\ntmap\ntidyverse\n\nAs maptools was removed from the CRAN repository, we can only install it through an archived link.\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nInstalling package into 'C:/Users/maste/AppData/Local/R/win-library/4.4'\n(as 'lib' is unspecified)\n\n\npackage 'maptools' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'maptools'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\maste\\AppData\\Local\\R\\win-library\\4.4\\00LOCK\\maptools\\libs\\x64\\maptools.dll\nto\nC:\\Users\\maste\\AppData\\Local\\R\\win-library\\4.4\\maptools\\libs\\x64\\maptools.dll:\nPermission denied\n\n\nWarning: restored 'maptools'\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\maste\\AppData\\Local\\Temp\\RtmpyGhUDZ\\downloaded_packages\n\n\nWe can now load the modules required\n\npacman::p_load(tmap, sf, raster, spatstat, maptools, sp, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "To answer these questions, we will be using the following datasets:\n\nMaster Plan 2014 Subzone Boundary Data\nChildcare Services (GeoJSON)\nCostalOutline from SLA\n\nWe first use st_read() to import all our into variables mpsz_sf,childcare_sf, sg_sf\n\nmpsz_sf &lt;- st_read(dsn = \"data\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform( crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex03\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nWe want all the data to be using the same projection system, thus, we have transformed our the childcare data to use SVY21."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#data-wrangling",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Now that we have all the data prepared, let’s plot a simple graph using them.\n\ntm_shape(sg_sf) + tm_polygons() + tm_shape(mpsz_sf) +\n  tm_polygons() + tm_shape(childcare_sf) + tm_dots()\n\n\n\n\n\n\n\n\nFor an interactive pin map, we can use the following code\n\n#tmap_mode('view')\n#tm_shape(childcare_sf) + tm_dots()\n#tmap_mode('plot')\n\n\n\n\nWe first want to convert our data to sp’s Spatial* class using sf as_Spatial\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nWe can then check the conversion\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\nAs we are unable to convert directly into ppp, we should first convert into the generic sp format\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nWe can then view the values\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\n\n\n\nchildcare_ppp &lt;- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nWe can now plot childcare_ppp and examine the difference\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nFrom the above summary, we can see that there are duplicated points. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n\nTo confirm the presence of duplicates, we can run the following code\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo view which points are duplicated we can use the multiplicity() function\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nWe only want to look at locations with &gt; 1 points. We can sum the total to find out how many points have duplicates.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nWith this, we know that there are 128 duplicated points. We can also view these points through this code chunk.\n\n#tmap_mode('view')\n#tm_shape(childcare) + \n  #tm_dots(alpha = 0.3, size = 0.05)\n#tmap_mode('plot')\n\nThere are generally 3 ways to resolve the issue with duplicated points\n\nDeleting the duplicates. This however has the issue of deleting useful points\nUsing Jittering to shift duplicated points so that they do not occupy the same space\nAttaching the duplicates to the patterns as “marks”. We would then need analytical techniques that take into account those “marks”\n\nWe will be using the Jittering approach\n\nchildcare_ppp &lt;- rjitter(childcare_ppp,\n                         retry = TRUE,\n                         nsimm = 1,\n                         drop = TRUE)\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\n\n\n\nDue to the importance of confining the analysis with a geographical area like the Singapore boundary while analysing spatial point patters, we can use an owin object from the spatstat package\n\nsg_owin &lt;- as.owin(sg_sf)\n\nWe can then plot the sg_owin variable\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nWe should also view the summary\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nAs mentioned previously, we want to confine out analysis only to Singapore. To do that, let’s combine childcare_ppp with sg_owin\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nAnd view the new plotted data\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-pattern-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#st-order-spatial-point-pattern-analysis",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "We will now explore how to perform 1st Order Spatial Point Pattern Analysis through the spatstat package. We will be focusing on 2 aspects of this.\n\nderiving kernel density estimation (KDE) layer for visualising and exploring the intensity of point processes\nperforming Confirmatory Spatial Point Patterns Analysis by using Nearest Neighbour statistics\n\n\n\n\n\nThe density() function from spatstat computes a kernal density for a given set of point events. We can use diggle() to automatically help us select a bandwith for computing kernel density\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nWith the output range from 0 to 0.000035 which is way too small to comprehend due to svy21 using meter as its default unit of measurement, we will need to rescale the values. To do this, we first need to retrieve the bandwith used\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n\nWe want to rescale our default unit of measurement to use km instead of m\n\nchildcareSG_ppp_km &lt;- rescale(childcareSG_ppp, 1000, \"km\")\nkde_childcareSG_bw &lt;- density(childcareSG_ppp_km, sigma = bw.diggle, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nNow we have an output with a legend that is easy to read.\n\n\n\n\nThere are 3 other functions from spatstat that can be used aside from diggle()\n\nbw.CvL()\nbw.scott()\nbw.ppl()\n\n\n\n\nbw.CvL(childcareSG_ppp_km)\n\n   sigma \n4.322776 \n\n\n\nkde_childcareSG_bw_CvL &lt;- density(childcareSG_ppp_km, sigma =  bw.CvL, edge = TRUE, kernel = \"gaussian\")\n\n\n\n\n\nbw.scott(childcareSG_ppp_km)\n\n sigma.x  sigma.y \n2.224962 1.451070 \n\n\n\nkde_childcareSG_bw_scott &lt;- density(childcareSG_ppp_km, sigma =  bw.scott, edge = TRUE, kernel = \"gaussian\")\n\n\n\n\n\nbw.ppl(childcareSG_ppp_km)\n\n    sigma \n0.3469986 \n\n\n\nkde_childcareSG_bw_ppl &lt;- density(childcareSG_ppp_km, sigma =  bw.ppl, edge = TRUE, kernel = \"gaussian\")\n\nNow we can compare with diggle()\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(kde_childcareSG_bw, main = \"bw.diggle\")\nplot(kde_childcareSG_bw_CvL, main = \"bw.CvL\")\nplot(kde_childcareSG_bw_scott, main = \"bw.scott\")\nplot(kde_childcareSG_bw_ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\nBy default, the kernel method used in density.ppp() is gaussian. However, there are 3 other options\n\nEpanechnikov\nQuartic\nDics\n\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"gaussian\"), main = \"Gaussian\")\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"epanechnikov\"), main = \"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"quartic\"), main = \"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, kernel = \"disc\"), main = \"Disc\")\n\nWarning in density.ppp(childcareSG_ppp_km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSince we want to use a bandwith of 600 meters, we will use a sigma value of 0.6 as childcare_ppp.km uses kilometers.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp_km, sigma = 0.6, edge = TRUE, kernel = \"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\n\n\n\nAs the fixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural, we can use adaptive bandwith to alleviate this.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp_km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can now compare both of them directly\n\npar(mfrow = c(1,2))\npar(mar = c(3,2,2,1))\nplot(kde_childcareSG_600, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\nWe do this to make it suitable for mapping purposes\n\ngridded_kde_childcareSG_bw &lt;- as.SpatialGridDataFrame.im(kde_childcareSG_bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\n\nWe can further convert this into a raster layer\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.28627e-15, 28.87893  (min, max)\n\n\nAs the crs now reads NA, we want to convert it back to using EPSG3414\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.28627e-15, 28.87893  (min, max)\n\n\n\n\n\n\nWe can now use the raster layer and display it in tmap\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"v\", palette=\"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n\n\n\nWe want to compare the KDE of Punggol, Tampines, Choa Chu Kang and Jurong West planning areas.\n\n\nWe first want to extract the areas that we are interested in\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nWe can plot the areas to check\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(pg, main = \"Punggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\nWe now want to convert them into owin objects\n\npg_owin &lt;- as.owin(pg)\ntm_owin &lt;- as.owin(tm)\nck_owin &lt;- as.owin(ck)\njw_owin &lt;- as.owin(jw)\n\nWe also want to extract out the childcare centre points within each of the areas\n\nchildcare_pg_ppp = childcare_ppp[pg_owin]\nchildcare_tm_ppp = childcare_ppp[tm_owin]\nchildcare_ck_ppp = childcare_ppp[ck_owin]\nchildcare_jw_ppp = childcare_ppp[jw_owin]\n\nRescale from m to km:\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nOverlay the childcare centres over the area\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\nWe now want to derive the bandwith using diggle()\n\npar(mfrow = c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\nWe can also use a fixed bandwith of 0.25km\n\npar(mfrow=c(2,2))\npar(mar = c(3,2,2,1))\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n\n\nWe want to perform the Clark-Evans test of aggregation:\n\nH0: Random distribution of childcare centres\nH1: Non-Random distribution of childcare centres\n\n\nclarkevans.test(childcareSG_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.56425, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe R value from the above result indicates clustering, and as p &lt; 0.05, H0 can be rejected.\n\n\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=sg_owin,\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79113, p-value = 8.174e-05\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe R value from the above result indicates clustering, and as p &lt; 0.05, H0 can be rejected.\n\n\n\n\nclarkevans.test(childcare_pg_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.89384, p-value = 0.05635\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p &lt; 0.05, H0 can be rejected.\n\n\n\n\nclarkevans.test(childcare_ck_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.9373, p-value = 0.1744\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p &gt; 0.05, H0 cannot be rejected.\n\n\n\n\nclarkevans.test(childcare_jw_ppp,\n                correction = \"none\",\n                clipregion = \"sg_owin\",\n                alternative = c(\"clustered\"),\n                nsim = 99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_jw_ppp\nR = 0.89493, p-value = 0.02968\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p &lt; 0.05, H0 can be rejected."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-with-the-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-with-the-g-function",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process with the G-Function",
    "text": "Analysing Spatial Point Process with the G-Function\nThe G function measures the distribution of the distances from an arbitrary even to its nearest event. We are interested in the Choa Chu Kang planning area\n\nChoa Chu Kang Planning Area\nWe use the Gest() function from spatstat to compute the G-function\n\nG_CK &lt;- Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Choa Chu Kang\nH1: Non-Random distribution of childcare centres in Choa Chu Kang\n\nReject H0 if p &lt; 0.001.\nWe use the envelope() function to perform a Monte Carlo test\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nWe can then plot the results\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\nTampines Planning Area\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Tampines\nH1: Non-Random distribution of childcare centres in Tampines\n\nReject H0 if p &lt; 0.001.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nWe can then plot the results\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-with-the-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-with-the-f-function",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process with the F-Function",
    "text": "Analysing Spatial Point Process with the F-Function\nThe F function estimates the empty space function F(r) or its hazard rate h(r) from a point pattern in a window of arbitrary shape. We will be using Fest() from spatstat to achieve this.\n\nChoa Chu Kang Planning Area\n\nF_CK &lt;- Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Choa Chu Kang\nH1: Non-Random distribution of childcare centres in Choa Chu Kang\n\nReject H0 if p &lt; 0.001.\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nWe can then plot the results\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\nTampines Planning Area\n\nF_tm &lt;- Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Tampines\nH1: Non-Random distribution of childcare centres in Tampines\n\nReject H0 if p &lt; 0.001.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using K-Function",
    "text": "Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. We will be using the Kest() function from spatstat. ### Choa Chu Kang Planning Area\n\nK_ck &lt;- Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Choa Chu Kang\nH1: Non-Random distribution of childcare centres in Choa Chu Kang\n\nReject H0 if p &lt; 0.001.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\nTampines Planning Area\n\nK_tm &lt;- Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Tampines\nH1: Non-Random distribution of childcare centres in Tampines\n\nReject H0 if p &lt; 0.001.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 3: 1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "Analysing Spatial Point Process Using L-Function",
    "text": "Analysing Spatial Point Process Using L-Function\nThe L function is a transformation of the K function, designed to help in identifying clustering or regularity in spatial point patterns. We will be using Lest() from spatstat to achieve this.\n\nChoa Chu Kang Planning Area\n\nL_ck &lt;- Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Choa Chu Kang\nH1: Non-Random distribution of childcare centres in Choa Chu Kang\n\nReject H0 if p &lt; 0.001.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\nTampines Planning Area\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\nPerform a complete Spatial Randomness Test with the following hypotheses:\n\nH0: Random distribution of childcare centres in Tampines\nH1: Non-Random distribution of childcare centres in Tampines\n\nReject H0 if p &lt; 0.001.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In spatial policy, a key objective for local governments and planners is to ensure an even distribution of development across the province. In this study, we will apply spatial statistical methods to determine whether development, as measured by GDP per capita, is evenly distributed in Hunan Province, China. If the distribution is uneven, we will explore whether spatial clustering exists, and, if so, identify where these clusters are located.\n\n\nWe will be using the following packages:\n\nsf\nspdep\ntmap\ntidyverse\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)\n\n\n\n\nWe will be using 2 data sets for this exercise\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/Hands-on_Ex/Hands-on_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nWe want to combine the data to update the hunan SpatialPolygonsDataFrame with the attribute fields of hunan2012\n\nhunan_join &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\nLet’s first visualise a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\nFirst, the basemap\n\nqtm(hunan_join)\n\n\n\n\n\n\n\n\nNow, let’s visualise a choropleth map\n\nequal &lt;- tm_shape(hunan_join) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan_join) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\nWe will now be computeing global spatial autocorrelation statistics and performing spatial complete randomness tests for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nWe will first be usign poly2nb() of spdep to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. The “queen” argument in the function accepts TRUE or FALSE. If not specified, the default is TRUE, meaning the function will return a list of first-order neighbors using the Queen criteria unless you set queen = FALSE.\nNow, let’s compute the Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan_join, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe report shows that Hunan has 88 area units. The most connected unit has 11 neighbors, while two units have only one neighbor.\n\n\n\nWe will assign equal weights to each neighboring polygon using style = \"W\", meaning each neighbor gets a weight of 1/(# of neighbors), and the weighted income values are summed. This method is straightforward but may skew results for polygons at the edges of the study area, as they have fewer neighbors. For simplicity, we’ll use style = \"W\", though more robust options, like style = \"B\", are available.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote\n\n\n\nImportant to note:\n\nThe style parameter can take the values “W”, “B”, “C”, “U”, “minmax”, and “S”. “B” is basic binary coding, “W” is row-standardized (sums over all links to n), “C” is globally standardized (sums over all links), “U” is equal to “C” divided by the number of neighbors, and “S” is a variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999).\nIf zero policy is TRUE, regions with no neighbors will get a zero-length weights vector, resulting in a lagged value of zero. This may or may not be appropriate depending on the analysis.\n\n\n\n\n\n\n\nThis is a measure of spatial autocorrelation, which assesses how similar or dissimilar values are across a geographic space. It helps determine if the pattern expressed is clustered, dispersed, or random. ### Test We can perform Moran’s test using moran.test() from spdep\n\nmoran.test(hunan_join$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan_join$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nA positive Moran’s I indicates that there is positive spatial autocorrelation. This means that areas with similar GDP per capita values tend to be near each other (spatial clustering of similar values). The expected value of Moran’s I under the null hypothesis (random spatial distribution) is close to zero, but slightly negative due to the nature of the randomisation. A very small p-value (much less than 0.05) strongly suggests rejecting the null hypothesis of no spatial autocorrelation.\nThus, there is significant evidence of positive spatial autocorrelation in GDP per capita across Hunan Province (p-value &lt; 0.05). This means that GDP per capita values tend to cluster spatially, with areas of similar economic development located near each other.\n\n\nWe can perform a permutation test for Moran’s I statistic using moran.mc() from spdep with 1000 simulations\n\nset.seed(1234)\nbperm= moran.mc(hunan_join$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan_join$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nWith the results being similar to our initial test, our previous observation is now comfirmed.\n\n\n\nWe will now use hist() and abline() of R Graphics to plot the distribution of statistical values from our Monte-Carlo simulation\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")\n\n\n\n\n\n\n\n\nWe could alternatively use ggplot2 to plot our histogram\n\nlibrary(ggplot2)\n\n# Assuming bperm$res contains the simulated Moran's I values\nsimulated_values &lt;- bperm$res\n\n# Create a data frame for ggplot2\ndf &lt;- data.frame(simulated_values)\n\n# Plot the histogram using ggplot2\nggplot(df, aes(x = simulated_values)) +\n  geom_histogram(binwidth = 0.02, fill = \"grey\", color = \"black\", alpha = 0.8) +\n  geom_vline(xintercept = 0, color = \"red\") +\n  labs(title = \"Simulated Moran's I\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe red vertical line represents the observed Moran’s I value of 0.30075. As it is higher than the majority of the simulated values, we can confirm the high spatial correlation.\n\n\n\n\nThis is a measure of spatial autocorrelation, focusing on local spatial relationships. It assesses whether similar or dissimilar values are clustered together in a geographic space.\n\n\nWe can perform Geary’s C test using geary() from spdep\n\ngeary.test(hunan_join$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan_join$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nWith a value of &lt;1, this suggests that similar values are clustered together\n\n\n\nWe can perform a permutation test for Geary’s C statistic using geary.mc() from spdep with 1000 simulations.\n\nset.seed(1234)\nbperm=geary.mc(hunan_join$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan_join$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nThese results again correlate with our initial test. Thus, GDP per capita values tend to cluster spatially, with areas of similar economic development located near each other.\n\n\n\nWe will now be plotting a histogram to visualise our statistics\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")\n\nabline(v=bperm$statistic, col=\"blue\", lwd=2)\n\n\n\n\n\n\n\n\nWe can see that our Geary C statistic differs greatly from most of the simulated values. Thus we can safely conclude that our data has strong spatial clustering.\n\n\n\n\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nWe use sp.correlogram() frpm spdep to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan_join$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan_join$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThrough the plot above, we can see that our data indicates strong postive spatial correlation at close distances indicated by lag 1 and 2. This tells us that neighboring areas tend to have similar GDP per capita values. Greater distances indicated by lag 5 and 6 showcases negative spatial autocorrelation. This tells us that areas farther apart are likely to have different GDP per capita values.\n\n\n\nWe use sp.correlogram() frpm spdep to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan_join$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan_join$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#packages",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "We will be using the following packages:\n\nsf\nspdep\ntmap\ntidyverse\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#data",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "We will be using 2 data sets for this exercise\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012.\n\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/Hands-on_Ex/Hands-on_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nWe want to combine the data to update the hunan SpatialPolygonsDataFrame with the attribute fields of hunan2012\n\nhunan_join &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\n\n\nLet’s first visualise a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\nFirst, the basemap\n\nqtm(hunan_join)\n\n\n\n\n\n\n\n\nNow, let’s visualise a choropleth map\n\nequal &lt;- tm_shape(hunan_join) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan_join) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "We will now be computeing global spatial autocorrelation statistics and performing spatial complete randomness tests for global spatial autocorrelation.\n\n\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nWe will first be usign poly2nb() of spdep to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. The “queen” argument in the function accepts TRUE or FALSE. If not specified, the default is TRUE, meaning the function will return a list of first-order neighbors using the Queen criteria unless you set queen = FALSE.\nNow, let’s compute the Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan_join, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe report shows that Hunan has 88 area units. The most connected unit has 11 neighbors, while two units have only one neighbor.\n\n\n\nWe will assign equal weights to each neighboring polygon using style = \"W\", meaning each neighbor gets a weight of 1/(# of neighbors), and the weighted income values are summed. This method is straightforward but may skew results for polygons at the edges of the study area, as they have fewer neighbors. For simplicity, we’ll use style = \"W\", though more robust options, like style = \"B\", are available.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nNote\n\n\n\nImportant to note:\n\nThe style parameter can take the values “W”, “B”, “C”, “U”, “minmax”, and “S”. “B” is basic binary coding, “W” is row-standardized (sums over all links to n), “C” is globally standardized (sums over all links), “U” is equal to “C” divided by the number of neighbors, and “S” is a variance-stabilizing scheme proposed by Tiefelsdorf et al. (1999).\nIf zero policy is TRUE, regions with no neighbors will get a zero-length weights vector, resulting in a lagged value of zero. This may or may not be appropriate depending on the analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#morans-i",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "This is a measure of spatial autocorrelation, which assesses how similar or dissimilar values are across a geographic space. It helps determine if the pattern expressed is clustered, dispersed, or random. ### Test We can perform Moran’s test using moran.test() from spdep\n\nmoran.test(hunan_join$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan_join$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nA positive Moran’s I indicates that there is positive spatial autocorrelation. This means that areas with similar GDP per capita values tend to be near each other (spatial clustering of similar values). The expected value of Moran’s I under the null hypothesis (random spatial distribution) is close to zero, but slightly negative due to the nature of the randomisation. A very small p-value (much less than 0.05) strongly suggests rejecting the null hypothesis of no spatial autocorrelation.\nThus, there is significant evidence of positive spatial autocorrelation in GDP per capita across Hunan Province (p-value &lt; 0.05). This means that GDP per capita values tend to cluster spatially, with areas of similar economic development located near each other.\n\n\nWe can perform a permutation test for Moran’s I statistic using moran.mc() from spdep with 1000 simulations\n\nset.seed(1234)\nbperm= moran.mc(hunan_join$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan_join$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nWith the results being similar to our initial test, our previous observation is now comfirmed.\n\n\n\nWe will now use hist() and abline() of R Graphics to plot the distribution of statistical values from our Monte-Carlo simulation\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")\n\n\n\n\n\n\n\n\nWe could alternatively use ggplot2 to plot our histogram\n\nlibrary(ggplot2)\n\n# Assuming bperm$res contains the simulated Moran's I values\nsimulated_values &lt;- bperm$res\n\n# Create a data frame for ggplot2\ndf &lt;- data.frame(simulated_values)\n\n# Plot the histogram using ggplot2\nggplot(df, aes(x = simulated_values)) +\n  geom_histogram(binwidth = 0.02, fill = \"grey\", color = \"black\", alpha = 0.8) +\n  geom_vline(xintercept = 0, color = \"red\") +\n  labs(title = \"Simulated Moran's I\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe red vertical line represents the observed Moran’s I value of 0.30075. As it is higher than the majority of the simulated values, we can confirm the high spatial correlation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#gearys-c",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "This is a measure of spatial autocorrelation, focusing on local spatial relationships. It assesses whether similar or dissimilar values are clustered together in a geographic space.\n\n\nWe can perform Geary’s C test using geary() from spdep\n\ngeary.test(hunan_join$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan_join$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nWith a value of &lt;1, this suggests that similar values are clustered together\n\n\n\nWe can perform a permutation test for Geary’s C statistic using geary.mc() from spdep with 1000 simulations.\n\nset.seed(1234)\nbperm=geary.mc(hunan_join$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan_join$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nThese results again correlate with our initial test. Thus, GDP per capita values tend to cluster spatially, with areas of similar economic development located near each other.\n\n\n\nWe will now be plotting a histogram to visualise our statistics\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")\n\nabline(v=bperm$statistic, col=\"blue\", lwd=2)\n\n\n\n\n\n\n\n\nWe can see that our Geary C statistic differs greatly from most of the simulated values. Thus we can safely conclude that our data has strong spatial clustering."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-correlogram",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Spatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n\nWe use sp.correlogram() frpm spdep to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan_join$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan_join$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThrough the plot above, we can see that our data indicates strong postive spatial correlation at close distances indicated by lag 1 and 2. This tells us that neighboring areas tend to have similar GDP per capita values. Greater distances indicated by lag 5 and 6 showcases negative spatial autocorrelation. This tells us that areas farther apart are likely to have different GDP per capita values.\n\n\n\nWe use sp.correlogram() frpm spdep to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan_join$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan_join$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-indicators-of-spatial-associationlisa",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#local-indicators-of-spatial-associationlisa",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Local Indicators of Spatial Association(LISA)",
    "text": "Local Indicators of Spatial Association(LISA)\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\n\nMoran’s I\nWe will compute this using the localmoran() function of spdep. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\n\nfips &lt;- order(hunan_join$County)\nlocalMI &lt;- localmoran(hunan_join$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nMapping\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame.\n\nhunan.localMI &lt;- cbind(hunan_join,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\nI values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\n\n\np-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nComparing I and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-a-lisa-cluster-map",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Creating a LISA cluster map",
    "text": "Creating a LISA cluster map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nMoran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nWe will use moran.plot() from spdep to plot this.\n\nnci &lt;- moran.plot(hunan_join$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nMoran scatterplot with standardised variable\nWe will use scale() to center and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\nWe use as.vector() at the end to make sure that the data type we get out of this is a vector, that maps neatly into out dataframe.\n\nhunan$Z.GDPPC &lt;- scale(hunan_join$GDPPC) %&gt;% \n  as.vector \n\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\nPreparing LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan_join$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\n\nsignif &lt;- 0.05       \n\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\nPlotting the LISA map\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\n\ngdppc &lt;- qtm(hunan_join, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\nprint(LISAmap)\n\n\n\n\n\n\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nThe LISA map shows clear patterns of spatial inequality in GDP per capita, with clusters of both wealth and poverty. High-high clusters in the east indicate areas of concentrated development, while low-low clusters in the west show areas that are lagging behind. The map highlights the uneven spatial distribution of economic development across Hunan Province."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving distance-based weight matrix\nirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere is both adaptive and fixed distance weight matrix.\n\nDeriving the centroid\nTo create our connectivity graph, we need to associate points with each polygon. This is more complex than just using st_centroid() on the us.bound sf object. We need to extract the coordinates into a separate data frame. To do this, we’ll use a mapping function that applies st_centroid() to each element in the geometry column of us.bound.\nWe’ll use map_dbl from the purrr package to extract the longitude values. By applying st_centroid() and accessing the longitude through [[1]], we get the first value (longitude) of each centroid.\n\nlongitude &lt;- map_dbl(hunan_join$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan_join$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\nDetermine the cut-off distance\nwe need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords))\n\nWarning in knn2nb(knearneigh(coords)): neighbour object has 25 sub-graphs\n\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\nComputing adaptive distance weight matrix\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-gi-statistics",
    "title": "Hands-on Exercise 6: Measures of Spatial Autocorrelation",
    "section": "Computing Gi Statistics",
    "text": "Computing Gi Statistics\n\nFixed Distance\n\nfips &lt;- order(hunan_join$County)\ngi.fixed &lt;- localG(hunan_join$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan_join$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNow we will join the Gi values to their corresponding hunan sf data frame,\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\nMapping\n\ngdppc &lt;- qtm(hunan_join, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nThe hot spots indicated by the dark red areas indicate clusters of high GDP per capita. The cold spots indicated by the blue areas showcase clusters of low GDP per capita. This again confirms our earlier conclusions of low and high clustering of regions within the Hunan province.\n\n\n\nAdaptive Distance\n\nfips &lt;- order(hunan_join$County)\ngi.adaptive &lt;- localG(hunan_join$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\nMapping\n\ngdppc&lt;- qtm(hunan_join, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nThe results are similar with the only big difference being a darker blue cold spot indicating a strong negative spatial autocorrelation."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "As maptools was removed from the CRAN repository, we can only install it through an archived link.\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nWe can now load the modules required\n\npacman::p_load(tmap, sf, raster, spatstat, maptools, sp, tidyverse)\n\nInstalling package into '/home/syoongy/R/x86_64-pc-linux-gnu-library/4.4'\n(as 'lib' is unspecified)\n\n\nWarning: package 'maptools' is not available for this version of R\n\nA version of this package for your version of R might be available elsewhere,\nsee the ideas at\nhttps://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages\n\n\nWarning: 'BiocManager' not available.  Could not check Bioconductor.\n\nPlease use `install.packages('BiocManager')` and then retry.\n\n\nWarning in p_install(package, character.only = TRUE, ...):\n\n\nWarning in library(package, lib.loc = lib.loc, character.only = TRUE,\nlogical.return = TRUE, : there is no package called 'maptools'\n\n\nWarning in pacman::p_load(tmap, sf, raster, spatstat, maptools, sp, tidyverse): Failed to install/load:\nmaptools"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#working-with-st_union",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#working-with-st_union",
    "title": "In-class Exercise 3",
    "section": "Working with st_union()",
    "text": "Working with st_union()\nWe want to derive the coastal outline sf tibble data.frame\n\nsg_sf &lt;- mpsz_sf %&gt;%\n  st_union()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nIn this exercise, we would like to learn about the following questions\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#study-area",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#study-area",
    "title": "In-class Exercise 4",
    "section": "Study Area",
    "text": "Study Area\n\nImporting\nWe first want to import our study area\n\nkbb &lt;- st_read(dsn = \"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe want to remove some redundant values\n\nkbb_sf &lt;- st_read(dsn = \"data/rawdata\",\n               layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;%\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `D:\\Coding\\is415\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nst_as_s2(): dropping Z and/or M coordinate\n\n\n\n\nPreparing\n\nConverting to OWIN\nWe want to convert kbb into an owin object\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nCheck if we have correctly converted the object\n\nclass(kbb_owin)\n\n[1] \"owin\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#forest-fire-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#forest-fire-data",
    "title": "In-class Exercise 4",
    "section": "Forest Fire Data",
    "text": "Forest Fire Data\n\nImporting\nWe now want to import the forest fire data\n\nfire_sf &lt;- read_csv(\"data/rawdata/forestfires.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nRows: 741 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): satellite, instrument, daynight\ndbl  (11): latitude, longitude, brightness, scan, track, acq_time, confidenc...\ndate  (1): acq_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nPreparing\nAs ppp objects only accept numerical or characters as mark, we need to convert the acq_date to numeric\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(DayofYear = yday(acq_date)) %&gt;%\n  mutate(Month_num = month(acq_date)) %&gt;%\n  mutate(Month_fac = month(acq_date,\n                          label = TRUE,\n                          abbr = FALSE))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#visualising",
    "title": "In-class Exercise 4",
    "section": "Visualising",
    "text": "Visualising\nWe now want to visualise our data with a plot of the study area overlaid with the forest fire data\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nWe also want to see how the data changes over the months\n\ntm_shape(kbb_sf) +\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots(size = 0.1) +\n  tm_facets(by=\"Month_fac\",\n              free.coords = FALSE,\n              drop.units = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#by-day",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#by-day",
    "title": "In-class Exercise 4",
    "section": "By Day",
    "text": "By Day\n\nExtracting forest fires by day\nWe first want to only select the month from the fire_sf variable\n\nfire_yday &lt;- fire_sf %&gt;%\n  dplyr::select(DayofYear)\n\n\n\nCreating ppp\nWe now want to convert this into ppp\n\nfire_yday_ppp &lt;- as.ppp(fire_yday)\nfire_yday_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\n\n\nIncluding Owin object\nWe also want to have an owin object\n\nfire_yday_owin &lt;- fire_yday_ppp[kbb_owin]\nsummary(fire_yday_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   10.0   213.0   258.0   245.9   287.0   352.0 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\n\nkde_yday &lt;- spattemp.density(\n  fire_yday_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(kde_yday)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 6.3198 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [10, 352]\n\nEvaluation\n  128 x 128 x 343 trivariate lattice\n  Density range: [3.959516e-27, 2.751287e-12]\n\n\n\nlength((st_kde))\n\n[1] 11"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse, sfdep)\n\n\nImport Geospatial Data\n\nhunan &lt;- st_read(dsn = \"data/geospatial\",\n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/In-class_Ex/In-class_Ex06/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhunan &lt;- left_join(hunan, hunan2012) |&gt;\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n\nhunan\n\nSimple feature collection with 88 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734...\n\n\n\nwrite_rds(hunan, \"data/rds/hunan.rds\")\n\n\nhunan &lt;- read_rds(\"data/rds/hunan.rds\")\n\n\nwm_q &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry), \n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nglobal moran’s I test\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nseed for consistency\n\nset.seed(777)\n\nglobal moran’s I permutation test\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nlocal moran’s I\n\nlisa &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nviz LMI & pval\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nviz lisa map\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nhot and cold (cantonese version)\nderive spatial weight matrix\n\nwm_idw &lt;- hunan %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\ncompute local Gi\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi    var_gi  std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0115   6.69e-6  0.00106 9.99e-1  0.84         0.42    1.21 \n 2 -0.333  Low     0.0107   6.09e-6 -0.101   9.19e-1  0.92         0.46    0.792\n 3  0.281  High    0.0123   8.52e-6 -0.0220  9.82e-1  0.78         0.39    0.805\n 4  0.411  High    0.0119   1.06e-5  0.216   8.29e-1  0.7          0.35    0.803\n 5  0.387  High    0.0116   8.61e-6  0.305   7.61e-1  0.62         0.31    1.07 \n 6 -0.368  High    0.0115   8.81e-6 -0.391   6.96e-1  0.8          0.4     1.17 \n 7  3.56   High    0.0149   6.87e-6  2.78    5.40e-3  0.04         0.02    0.991\n 8  2.52   High    0.0132   4.78e-6  1.86    6.28e-2  0.1          0.05    0.734\n 9  4.56   High    0.0144   5.87e-6  3.52    4.34e-4  0.02         0.01    0.602\n10  1.16   Low     0.0104   3.82e-6  1.78    7.43e-2  0.08         0.04    1.12 \n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\nviz Gi\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\", palette = \"-RdBu\", style = \"cont\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nviz pval\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nviz hcsa\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\", palette = \"-RdBu\", style = \"cont\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\n\n\n\nplot signif hot/cold areas\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\", palette = \"-RdBu\", style = \"cont\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades.\nSource: 10 Conflicts to Watch in 2024\nIn this article, we are going to be primarily focusing on the ongoing Myanmar Civil War which started in 2021. This civil war comes after Myanmar’s long history of insurgencies post independence from British Rule. It had escalated significantly after the 2021 coup d’état on 1 February 2021 which saw the Tatmadaw (Myanmar’s Military) overthrow the ruling party at the time."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#import",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#import",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Import",
    "text": "Import\nWe first want to load in the conflict data ranging from 2021-2024\n\nconflict2124_sf &lt;- read_csv(\"data/2021-01-01-2024-06-30-Myanmar.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\nRows: 51553 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): event_id_cnty, event_date, disorder_type, event_type, sub_event_ty...\ndbl (11): year, time_precision, inter1, inter2, interaction, iso, latitude, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe also want to import our shapefile of administrative area 1\n\nmadm1_sf &lt;- st_read(dsn = \"data/geospatial\", layer = \"mmr_polbnda2_adm1_250k_mimu_1\") %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/Take-home_EX/Take-home_Ex01/data/geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nFinally, we have the data from OpenStreetMap where we will focus on places\n\nosm_sf &lt;- st_read(\"data/geospatial/myanmar-latest-free.shp\",\n                      layer=\"gis_osm_places_a_free_1\") %&gt;%\n  st_transform(crs = 32647)\n\nReading layer `gis_osm_places_a_free_1' from data source \n  `/home/syoongy/Documents/code/SMU/is415/IS415-GAA/Take-home_EX/Take-home_Ex01/data/geospatial/myanmar-latest-free.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 10497 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.24155 ymin: 9.606004 xmax: 101.0663 ymax: 28.17021\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#wrangling",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#wrangling",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Wrangling",
    "text": "Wrangling\n\nConflict Data\nWe also want to add a column called quarter on our conflict2124_sf dataset to help when breaking down the data into yearly quarters. We will achieve this through the quarter() function from lubridate.\n\nconflict2124_sf &lt;- conflict2124_sf %&gt;% \n  mutate(event_date = dmy(event_date),quarter = quarter(event_date))\n\n\n\nAdministrative Area 1\nWe first want to rename our states from myanmaradm1 to have the same naming scheme as conflict2124\n\nmadm1_sf$ST &lt;- gsub(\"\\\\s*\\\\(([^)]+)\\\\)\", \"-\\\\1\", madm1_sf$ST)\n\n\n\nOpenStreetMap\nWith the OSM dataset being so large, we want to cut down on the dataset to only data that would be useful for our exploration. Let’s first look at the different types of places available from our dataset by finding the unique values in the fclass column\n\nunique(osm_sf$fclass)\n\n [1] \"island\"   \"town\"     \"village\"  \"city\"     \"suburb\"   \"hamlet\"  \n [7] \"locality\" \"farm\"     \"county\"   \"region\"  \n\n\nWe can now cut out the place types that are irrelevant to us and also remove unnecessary columns\n\nplaces_to_keep &lt;- c(\"village\", \"town\", \"city\")\n\n\nosm_sf &lt;- osm_sf %&gt;%\n  filter(fclass %in%  places_to_keep) %&gt;%\n  dplyr::select(\"osm_id\", \"fclass\")\n\n\nsummary(osm_sf)\n\n    osm_id             fclass                   geometry   \n Length:9513        Length:9513        MULTIPOLYGON :9513  \n Class :character   Class :character   epsg:32647   :   0  \n Mode  :character   Mode  :character   +proj=utm ...:   0  \n\n\n\n\nJoining Geospatial Data\nWe now want to combine both our geospatial datasets\n\nmyanmar_merged &lt;- st_intersection(osm_sf, madm1_sf)\n\n\nsummary(myanmar_merged)\n\nLet’s now save this data\n\nwrite_rds(myanmar_merged, \"data/rds/myanmar_merged.rds\")\n\n\nmyanmar_merged_sf &lt;- read_rds(\"data/rds/myanmar_merged.rds\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = 32647)\n\n\nsummary(myanmar_merged_sf)\n\n    osm_id             fclass             OBJECTID           ST           \n Length:9517        Length:9517        Min.   : 1.000   Length:9517       \n Class :character   Class :character   1st Qu.: 8.000   Class :character  \n Mode  :character   Mode  :character   Median : 9.000   Mode  :character  \n                                       Mean   : 8.924                     \n                                       3rd Qu.:13.000                     \n                                       Max.   :18.000                     \n   ST_PCODE            ST_RG              ST_MMR             PCode_V   \n Length:9517        Length:9517        Length:9517        Min.   :9.4  \n Class :character   Class :character   Class :character   1st Qu.:9.4  \n Mode  :character   Mode  :character   Mode  :character   Median :9.4  \n                                                          Mean   :9.4  \n                                                          3rd Qu.:9.4  \n                                                          Max.   :9.4  \n          geometry   \n MULTIPOLYGON :   3  \n POLYGON      :9514  \n epsg:32647   :   0  \n +proj=utm ...:   0  \n                     \n                     \n\n\nFinally, let’s turn this into\n\n\nVisualisation\nWe can first view the basemap of myanmar and its conflicts data combined through the use of tmap methods split year on year\n\ntm_shape(madm1_sf) +\n  tm_polygons() +\n  tm_shape(conflict2124_sf) +\n  tm_dots() +\n  tm_facets(by=\"year\",\n              free.coords = FALSE,\n              drop.units = TRUE)\n\n\n\n\n\n\n\n\nAt a glance, we can see intense conflicts in years 2021 and 2022 which slowly decreased over time in years 2023 and 2024. This lines up with the timeline in which the military overthrew the ruling government which would liekly lead to higher rates of conflict. As time went on, these conflicts would decrease as the military would be actively taking down any opposition forces. As we do not have the full year of 2024, we are unable to determine a further decrease.\n\n\nPPP\nAs we will be looking at KDE data, we want to convert our conflict data into PPP objects\n\nconflict2124_ppp &lt;- conflict2124_sf %&gt;% {as.ppp(st_coordinates(.), st_bbox(.))}\n\nWarning: data contain duplicated points\n\n\n\nsummary(conflict2124_ppp)\n\nPlanar point pattern:  51553 points\nAverage intensity 3.12815e-08 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 13 decimal places\n\nWindow: rectangle = [-208804.4, 640934.5] x [1103500.1, 3042960.3] units\n                    (849700 x 1939000 units)\nWindow area = 1.64803e+12 square units\n\n\nLet’s first create an object to store all our split data called conflict2124_ppp_list and add in the years we want to look at\n\nconflict2124_ppp_list &lt;- list(\n  \"2021\" = list(\n    \"Q1\" = list(),\n    \"Q2\" = list(),\n    \"Q3\" = list(),\n    \"Q4\" = list()\n  ),\n  \"2022\" = list(\n    \"Q1\" = list(),\n    \"Q2\" = list(),\n    \"Q3\" = list(),\n    \"Q4\" = list()\n  ),\n  \"2023\" = list(\n    \"Q1\" = list(),\n    \"Q2\" = list(),\n    \"Q3\" = list(),\n    \"Q4\" = list()\n  ),\n  \"2024\" = list(\n    \"Q1\" = list(),\n    \"Q2\" = list(),\n    \"Q3\" = list(),\n    \"Q4\" = list()\n  )\n)\n\nWe now want to assign our filtered quarter data into each of the years\n\nfor (targetyear in 2021:2024) {\n  for (targetquarter in 1:4) {\n    quarter_name &lt;- paste0(\"Q\", targetquarter)\n    filtered_data &lt;- conflict2124_sf %&gt;%\n      filter(year == as.character(targetyear) & quarter == as.character(targetquarter))\n    \n    if (nrow(filtered_data) &gt; 0) {\n      conflict2124_ppp_list[[as.character(targetyear)]][[quarter_name]] &lt;- as.ppp(st_coordinates(filtered_data), st_bbox(filtered_data))\n    }\n  }\n}\n\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\n\n\n\nDeduplication\nAs we get a warning of duplicated points, we should aim to remove as many as possible. Let’s first find out how many duplicated points we have through the use of sum() and multiplicity().\n\nsum(multiplicity(conflict2124_ppp) &gt; 1)\n\n[1] 48258\n\n\nLet’s now remove these points using rjitter() to shift our points slightly.\n\nconflict2124_ppp &lt;- rjitter(conflict2124_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nWe can now use any() and duplicated() to check if there are still duplicated points\n\nany(duplicated(conflict2124_ppp))\n\n[1] FALSE\n\n\nWe want to repeat this with the values in our ppp_list too\n\nfor (targetyear in names(conflict2124_ppp_list)) {\n  for (targetquarter in names(conflict2124_ppp_list[[targetyear]])) {\n    ppp_obj &lt;- conflict2124_ppp_list[[as.character(targetyear)]][[targetquarter]]\n    if (class(ppp_obj) == \"ppp\") {\n      # Apply rjitter() to the ppp_obj\n      jittered_ppp &lt;- rjitter(ppp_obj, retry = TRUE, nsim = 1, drop = TRUE)\n      \n      # Assign the jittered ppp object back to the list\n      conflict2124_ppp_list[[as.character(targetyear)]][[targetquarter]] &lt;- jittered_ppp\n      print(any(duplicated(conflict2124_ppp_list[[as.character(targetyear)]][[targetquarter]])))\n    }\n  }\n}\n\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n\n\n\n\n\nOwin\nWe also want to create an owin object to ensure that all points we are looking at are within the Myanmar boundary.\n\nmadm1_owin &lt;- as.owin(madm1_sf)\n\n\nplot(madm1_owin)\n\n\n\n\n\n\n\n\nNow let’s combine this with our conflict data\n\nconflict2124_ppp_list &lt;- lapply(conflict2124_ppp_list, function(year_data_list) {\n  lapply(year_data_list, function(quarter_data) {\n    if (class(quarter_data) == \"ppp\")\n      quarter_data[madm1_owin]\n  })\n})\n\n\nplot(conflict2124_ppp_list$\"2024\"$Q1)\n\n\n\n\n\n\n\n\n\nplot(conflict2124_ppp_list$\"2024\"$Q2)"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#automatic-bandwith",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#automatic-bandwith",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Automatic Bandwith",
    "text": "Automatic Bandwith\nLet’s first compare using the bandwith functions of diggle, CvL, ppl, scott,\n\nbw.digglebw.CvLbw.pplbw.scott\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=bw.CvL, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#manual-bandwith",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#manual-bandwith",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Manual Bandwith",
    "text": "Manual Bandwith\nWe can also look at how our KDE will look with some manual values\n\nSignma 10Signma 20Signma 30\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=10, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=20, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nconflict.bw &lt;- density(conflict2124_ppp_list.km$\"2021\"$Q1,\n             sigma=30, \n             edge=TRUE, \n             kernel=\"gaussian\")\nplot(conflict.bw)\n\n\n\n\n\n\n\n\n\n\n\nWhen looking at the results, scott looks to give the best results. So for the next portions we will be using that.\n\n2021202220232024\n\n\n\npar(mfrow=c(2,2))\nplot(density(conflict2124_ppp_list.km$\"2021\"$Q1, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q1\")\nplot(density(conflict2124_ppp_list.km$\"2021\"$Q2, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q2\")\nplot(density(conflict2124_ppp_list.km$\"2021\"$Q3, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q3\")\nplot(density(conflict2124_ppp_list.km$\"2021\"$Q4, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2021 Q4\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(conflict2124_ppp_list.km$\"2022\"$Q1, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q1\")\nplot(density(conflict2124_ppp_list.km$\"2022\"$Q2, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q2\")\nplot(density(conflict2124_ppp_list.km$\"2022\"$Q3, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q3\")\nplot(density(conflict2124_ppp_list.km$\"2022\"$Q4, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2022 Q4\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(conflict2124_ppp_list.km$\"2023\"$Q1, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q1\")\nplot(density(conflict2124_ppp_list.km$\"2023\"$Q2, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q2\")\nplot(density(conflict2124_ppp_list.km$\"2023\"$Q3, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q3\")\nplot(density(conflict2124_ppp_list.km$\"2023\"$Q4, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2023 Q4\")\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(density(conflict2124_ppp_list.km$\"2024\"$Q1, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2024 Q1\")\nplot(density(conflict2124_ppp_list.km$\"2024\"$Q2, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"2024 Q2\")"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#scope",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#scope",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Scope",
    "text": "Scope\nI would like to scope down to the Sagaing Region as it has been a hotspot for clashes between the military and armed resistance groups.\nWe first need to retrieve our Sagaing data as an sf object\n\nsagaing_sf &lt;- madm1_sf %&gt;%\n  filter(ST == \"Sagaing\")\n\nWe can now create an owin object using this\n\nsagaing_owin &lt;- as.owin(sagaing_sf)\n\n\nplot(sagaing_owin)"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#ppp-1",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#ppp-1",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "PPP",
    "text": "PPP\nWe want to now retrieve PPP objects for the different types of conflicts based on each year. This will help us see the change over time regarding the different types of conflicts.\nLet’s first create a list to store this data. This will contain 4 different categories of battles, explosion/remote violence, strategic developments, violence against civilians.\n\nconflict_sagaing_ppp_list &lt;- list(\n  \"2021\" = list(\n    \"Battles\" = list(),\n    \"Explosions/Remote violence\" = list(),\n    \"Strategic developments\" = list(),\n    \"Violence against civilians\" = list()\n  ),\n  \"2022\" = list(\n    \"Battles\" = list(),\n    \"Explosions/Remote violence\" = list(),\n    \"Strategic developments\" = list(),\n    \"Violence against civilians\" = list()\n  ),\n  \"2023\" = list(\n    \"Battles\" = list(),\n    \"Explosions/Remote violence\" = list(),\n    \"Strategic developments\" = list(),\n    \"Violence against civilians\" = list()\n  ),\n  \"2024\" = list(\n    \"Battles\" = list(),\n    \"Explosions/Remote violence\" = list(),\n    \"Strategic developments\" = list(),\n    \"Violence against civilians\" = list()\n  )\n)\n\nLet’s now assign the data\n\nfor (targetyear in 2021:2024) {\n  for (targetevent in names(conflict_sagaing_ppp_list[[as.character(targetyear)]])) {\n    filtered_data &lt;- conflict2124_sf %&gt;%\n      filter(year == as.character(targetyear) & event_type == targetevent)\n    \n    if (nrow(filtered_data) &gt; 0) {\n      conflict_sagaing_ppp_list[[as.character(targetyear)]][[targetevent]] &lt;- as.ppp(st_coordinates(filtered_data), st_bbox(filtered_data))\n    }\n  }\n}\n\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\nWarning: data contain duplicated points\n\n\n\nDeduplication\n\nfor (targetyear in names(conflict_sagaing_ppp_list)) {\n  for (targetevent in names(conflict_sagaing_ppp_list[[targetyear]])) {\n    ppp_obj &lt;- conflict_sagaing_ppp_list[[as.character(targetyear)]][[targetevent]]\n    if (class(ppp_obj) == \"ppp\") {\n      # Apply rjitter() to the ppp_obj\n      jittered_ppp &lt;- rjitter(ppp_obj, retry = TRUE, nsim = 1, drop = TRUE)\n      \n      # Assign the jittered ppp object back to the list\n      conflict_sagaing_ppp_list[[as.character(targetyear)]][[targetevent]] &lt;- jittered_ppp\n      print(any(duplicated(conflict_sagaing_ppp_list[[as.character(targetyear)]][[targetevent]])))\n    }\n  }\n}\n\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE\n[1] FALSE"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#sagaing-conflict-data",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#sagaing-conflict-data",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Sagaing Conflict Data",
    "text": "Sagaing Conflict Data\nNow that we have removed the duplicates, we can now scope down our data further to only look at the armed conflict in Sagaing\n\nconflict_sagaing_ppp_list &lt;- lapply(conflict_sagaing_ppp_list, function(year_data_list) {\n  lapply(year_data_list, function(event_data) {\n    if (class(event_data) == \"ppp\")\n      event_data[sagaing_owin]\n  })\n})"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#g-function",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#g-function",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "G-Function",
    "text": "G-Function\nThe G function measures the distribution of the distances from an arbitrary even to its nearest event.\n\nBattles\n\n2021202220232024\n\n\n\nG_battles_2021 &lt;- Gest(conflict_sagaing_ppp_list$\"2021\"$Battles, correction = \"border\")\nplot(G_battles_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2022 &lt;- Gest(conflict_sagaing_ppp_list$\"2022\"$Battles, correction = \"border\")\nplot(G_battles_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2023 &lt;- Gest(conflict_sagaing_ppp_list$\"2023\"$Battles, correction = \"border\")\nplot(G_battles_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_battles_2024 &lt;- Gest(conflict_sagaing_ppp_list$\"2024\"$Battles, correction = \"border\")\nplot(G_battles_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplosion/Remote Violence\n\n2021202220232024\n\n\n\nG_explosives_2021 &lt;- Gest(conflict_sagaing_ppp_list$\"2021\"$`Explosions/Remote violence`, correction = \"border\")\nplot(G_explosives_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_explosives_2022 &lt;- Gest(conflict_sagaing_ppp_list$\"2022\"$`Explosions/Remote violence`, correction = \"border\")\nplot(G_explosives_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_explosives_2023 &lt;- Gest(conflict_sagaing_ppp_list$\"2023\"$`Explosions/Remote violence`, correction = \"border\")\nplot(G_explosives_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_explosives_2024 &lt;- Gest(conflict_sagaing_ppp_list$\"2024\"$`Explosions/Remote violence`, correction = \"border\")\nplot(G_explosives_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrategic Developments\n\n2021202220232024\n\n\n\nG_sd_2021 &lt;- Gest(conflict_sagaing_ppp_list$\"2021\"$`Strategic developments`, correction = \"border\")\nplot(G_sd_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_sd_2022 &lt;- Gest(conflict_sagaing_ppp_list$\"2022\"$`Strategic developments`, correction = \"border\")\nplot(G_sd_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_sd_2023 &lt;- Gest(conflict_sagaing_ppp_list$\"2023\"$`Strategic developments`, correction = \"border\")\nplot(G_sd_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_sd_2024 &lt;- Gest(conflict_sagaing_ppp_list$\"2024\"$`Strategic developments`, correction = \"border\")\nplot(G_sd_2024, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\n\n\nViolence against civilians\n\n2021202220232024\n\n\n\nG_VaC_2021 &lt;- Gest(conflict_sagaing_ppp_list$\"2021\"$`Violence against civilians`, correction = \"border\")\nplot(G_VaC_2021, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_VaC_2022 &lt;- Gest(conflict_sagaing_ppp_list$\"2022\"$`Violence against civilians`, correction = \"border\")\nplot(G_VaC_2022, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_VaC_2023 &lt;- Gest(conflict_sagaing_ppp_list$\"2023\"$`Violence against civilians`, correction = \"border\")\nplot(G_VaC_2023, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n\nG_VaC_2024 &lt;- Gest(conflict_sagaing_ppp_list$\"2024\"$`Violence against civilians`, correction = \"border\")\nplot(G_VaC_2024, xlim=c(0,500))"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#complete-spatial-randomness-test",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#complete-spatial-randomness-test",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Complete Spatial Randomness Test",
    "text": "Complete Spatial Randomness Test\nTo see if the the different event types are cluster or randomly dispersed. The hypothesis and test are as follows:\nHo = The distribution of a certain event at Sagaing region are randomly distributed.\nH1 = The distribution of a certain event at Sagaing region are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\n\nBattles\n\n2021\n\n\n\nset.seed(448)\nG_battles_2021.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2021\"$Battles, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_battles_2021.csr)\n\n\n\n\n\n\n\n\n\n2022\n\nset.seed(448)\nG_battles_2022.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2022\"$Battles, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_battles_2022.csr)\n\n\n\n\n\n\n\n\n\n\n2023\n\nset.seed(448)\nG_battles_2023.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2023\"$Battles, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_battles_2023.csr)\n\n\n\n\n\n\n\n\n\n\n2024\n\nset.seed(448)\nG_battles_2024.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2024\"$Battles, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_battles_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\n\nWith all the results across the years being above the envelope, we can conclude that conflicts relating to battle are highly clustered within the Sagaing region\n\n\nExplosion/Remote violence\n\n2021202220232024\n\n\n\nset.seed(448)\nG_explosives_2021.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2021\"$`Explosions/Remote violence`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_explosives_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_explosives_2022.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2022\"$`Explosions/Remote violence`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_explosives_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_explosives_2023.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2023\"$`Explosions/Remote violence`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_explosives_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_explosives_2024.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2024\"$`Explosions/Remote violence`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_explosives_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nWe see a smilar story with explosives where across the years all values are above the envelope which means these events are clustered.\n\n\nStrategic Developments\n\n2021202220232024\n\n\n\nset.seed(448)\nG_sd_2021.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2021\"$`Strategic developments`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_sd_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_sd_2022.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2022\"$`Strategic developments`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_sd_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_sd_2023.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2023\"$`Strategic developments`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_sd_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_sd_2024.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2024\"$`Strategic developments`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_sd_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nAgain, we see a similar trend with strategic developments where they are clustered across all years. ### Violence against civilians\n\n2021202220232024\n\n\n\nset.seed(448)\nG_VaC_2021.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2021\"$`Violence against civilians`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_VaC_2021.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_VaC_2022.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2022\"$`Violence against civilians`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_VaC_2022.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_VaC_2023.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2023\"$`Violence against civilians`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_VaC_2023.csr)\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nG_VaC_2024.csr &lt;- envelope(conflict_sagaing_ppp_list$\"2024\"$`Violence against civilians`, Gest, nsim = 99)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(G_VaC_2024.csr)\n\n\n\n\n\n\n\n\n\n\n\nBy this point, it is safe to conclude that all events within this region are highly clustered. This likely indicates that the region itself is a hotspot for these events ## KDE on OpenStreetMap\n\ntest_density &lt;- density(conflict_sagaing_ppp_list$\"2022\"$Battles, \n             sigma=bw.scott, \n             edge=TRUE, \n             kernel=\"gaussian\")\n\n\ndensity_raster &lt;- raster(test_density)\nprojection(density_raster) &lt;- CRS(\"+init=EPSG:32647\")\n\n\ntm_shape(density_raster) +\n  tm_raster() +\n  tm_shape(myanmar_merged_sf %&gt;% filter(ST == \"Sagaing\")) +\n  tm_dots()\n\nVariable(s) \"NA\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\nLegend labels were too wide. The labels have been resized to 0.33, 0.33, 0.33, 0.33. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#insights",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#insights",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Insights",
    "text": "Insights\nIn the Sagaing region, conflicts are commonplace with all types of conflicts ranging from violence to explosives being constant and clustered throughout the years. We can see most of the conflicts near the bottom of Sagaing and are towards the center of Myanmar which is also where a lot of conflicts within our data are clustered."
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#deduplication-2",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#deduplication-2",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Deduplication",
    "text": "Deduplication\n\nstkde_list_ppp &lt;- lapply(stkde_list_ppp, function(year_data) {\n  rjitter(year_data, \n           retry=TRUE, \n           nsim=1, \n           drop=TRUE)\n})"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#combined-data",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#combined-data",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Combined Data",
    "text": "Combined Data\nNow let’s combine our data with the madm1_owin object\n\nstkde_list_ppp &lt;- lapply(stkde_list_ppp, function(year_data) {\n  year_data[madm1_owin]\n})\n\n\nfor(targetyear in names(stkde_list_ppp)) {\n  plot(stkde_list_ppp[[as.character(targetyear)]], main = as.character(targetyear))\n}"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#plotting",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#plotting",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Plotting",
    "text": "Plotting\nNow we can finally plot the STKDE using spattemp.density()\n\n2021202220232024\n\n\n\nconflict_kde_2021 &lt;- spattemp.density(stkde_list_ppp$\"2021\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2021)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 50178.08 (spatial)\n  lambda = 0.0013 (temporal)\n\nNo. of observations\n  16180 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [7.381323e-14, 2.161734e-09]\n\n\n\n\n\nconflict_kde_2022 &lt;- spattemp.density(stkde_list_ppp$\"2022\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2022)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 45214.96 (spatial)\n  lambda = 0.0014 (temporal)\n\nNo. of observations\n  15897 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [7.950001e-18, 2.238789e-09]\n\n\n\n\n\nconflict_kde_2023 &lt;- spattemp.density(stkde_list_ppp$\"2023\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2023)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 53219.16 (spatial)\n  lambda = 0.0017 (temporal)\n\nNo. of observations\n  13184 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 4]\n\nEvaluation\n  128 x 128 x 4 trivariate lattice\n  Density range: [4.964293e-20, 1.527497e-09]\n\n\n\n\n\nconflict_kde_2024 &lt;- spattemp.density(stkde_list_ppp$\"2024\")\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(conflict_kde_2024)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 64197.39 (spatial)\n  lambda = 8e-04 (temporal)\n\nNo. of observations\n  5985 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [-210008.6, 724647.6] x [1072026, 3158467]\n\nTemporal bound\n  [1, 2]\n\nEvaluation\n  128 x 128 x 2 trivariate lattice\n  Density range: [1.004413e-12, 4.489329e-09]\n\n\n\n\n\nLet’s finally plot the STKDE graphs\n\n2021202220232024\n\n\n\ntims &lt;- c(1,2,3,4)\n\npar(mfrow=c(1,4), cex.main = 1.5)\nfor(i in tims){\n  plot(conflict_kde_2021, i, \n       fix.range=TRUE,\n       override.par=FALSE,\n       main=paste(\"STKDE Q\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,4), cex.main = 1.5)\nfor(i in tims){\n  plot(conflict_kde_2022, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"STKDE Q\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,4),cex.main = 1.5)\n\nfor(i in tims){\n  plot(conflict_kde_2023, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"STKDE Q\",i))\n}\n\n\n\n\n\n\n\n\n\n\n\ntims_2 &lt;- c(1,2)\n\npar(mfrow=c(1,2), cex.main = 1.2)\nfor(i in tims_2){\n  plot(conflict_kde_2024, i, \n       override.par=FALSE, \n       fix.range=TRUE,\n       main=paste(\"STKDE Q\",i))\n}"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#nd-order-stkde",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#nd-order-stkde",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "2nd Order STKDE",
    "text": "2nd Order STKDE\nFor this, we will be focusing again on the conflicts in the Sagaing region in 2024\n\nconflict_sagaing_2024_ppp_list &lt;- list(\n    \"Battles\" = NULL,\n    \"Explosions/Remote violence\" = NULL,\n    \"Strategic developments\" = NULL,\n    \"Violence against civilians\" = NULL\n  \n)\n\nLet’s now assign the data\n\nfor (targetevent in names(conflict_sagaing_2024_ppp_list)) {\n  filtered_data &lt;- conflict2124_sf %&gt;%\n    filter(year == \"2024\" & event_type == targetevent)\n  \n  if (nrow(filtered_data) &gt; 0) {\n    conflict_sagaing_2024_ppp_list[[targetevent]] &lt;- as.ppp(filtered_data)\n  }\n}\n\nWarning in as.ppp.sf(filtered_data): only first attribute column is used for\nmarks\nWarning in as.ppp.sf(filtered_data): only first attribute column is used for\nmarks\nWarning in as.ppp.sf(filtered_data): only first attribute column is used for\nmarks\nWarning in as.ppp.sf(filtered_data): only first attribute column is used for\nmarks\n\n\nWe once again deduplicate\n\nconflict_sagaing_2024_ppp_list &lt;- lapply(conflict_sagaing_2024_ppp_list, function(event) {\n  rjitter(event, \n           retry=TRUE, \n           nsim=1, \n           drop=TRUE)\n})\n\nAnd scope it down to Sagaing\n\nconflict_sagaing_2024_ppp_list &lt;- lapply(conflict_sagaing_2024_ppp_list, function(event) {\n  event[sagaing_owin]\n})\n\n\nBattleExplosion/Remote violenceStrategic DevelopmentViolence against civilians\n\n\n\nK_battle = Kest(conflict_sagaing_2024_ppp_list$Battles, correction = \"Ripley\")\nplot(K_battle, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nK_explosion = Kest(conflict_sagaing_2024_ppp_list$`Explosions/Remote violence`, correction = \"Ripley\")\nplot(K_explosion, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nK_Strat = Kest(conflict_sagaing_2024_ppp_list$`Strategic developments`, correction = \"Ripley\")\nplot(K_Strat, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nK_violence = Kest(conflict_sagaing_2024_ppp_list$`Violence against civilians`, correction = \"Ripley\")\nplot(K_violence, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n\nFinally let’s run the CSR simulation and plot it. If its\n\nAbove the envelop: significant cluster pattern\nBelow the envelop: significant regular\nInside the envelop: CSR\n\n\nBattlesExplosion/Remote violenceStrategic DevelopmentViolence against civilians\n\n\n\nset.seed(448)\nK_battle.csr &lt;- envelope(conflict_sagaing_2024_ppp_list$Battles, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [4:56 remaining] 3,\n [4:13 remaining] 4,  [4:06 remaining] 5,  [4:03 remaining] 6,\n [3:58 remaining] 7,  [3:56 remaining] 8,  [3:57 remaining] 9,\n [3:50 remaining] 10,  [3:46 remaining] 11,  [3:42 remaining] 12,\n [3:43 remaining] 13,  [3:37 remaining] 14,  [3:35 remaining] 15,\n [3:31 remaining] 16,  [3:27 remaining] 17,  [3:25 remaining] 18,\n [3:24 remaining] 19,  [3:21 remaining] 20,  [3:19 remaining] 21,\n [3:16 remaining] 22,  [3:13 remaining] 23,  [3:11 remaining] 24,\n [3:08 remaining] 25,  [3:06 remaining] 26,  [3:04 remaining] 27,\n [3:01 remaining] 28,  [2:59 remaining] 29,  [2:56 remaining] 30,\n [2:54 remaining] 31,  [2:53 remaining] 32,  [2:53 remaining] 33,\n [2:52 remaining] 34,  [2:49 remaining] 35,  [2:47 remaining] 36,\n [2:44 remaining] 37,  [2:42 remaining] 38,  [2:39 remaining] 39,\n [2:36 remaining] 40,  [2:33 remaining] 41,  [2:31 remaining] 42,\n [2:28 remaining] 43,  [2:26 remaining] 44,  [2:23 remaining] 45,\n [2:20 remaining] 46,  [2:17 remaining] 47,  [2:14 remaining] 48,\n [2:12 remaining] 49,  [2:09 remaining] 50,  [2:06 remaining] 51,\n [2:04 remaining] 52,  [2:01 remaining] 53,  [1:59 remaining] 54,\n [1:57 remaining] 55,  [1:55 remaining] 56,  [1:52 remaining] 57,\n [1:49 remaining] 58,  [1:47 remaining] 59,  [1:44 remaining] 60,\n [1:42 remaining] 61,  [1:39 remaining] 62,  [1:37 remaining] 63,\n [1:34 remaining] 64,  [1:31 remaining] 65,  [1:29 remaining] 66,\n [1:26 remaining] 67,  [1:24 remaining] 68,  [1:21 remaining] 69,\n [1:18 remaining] 70,  [1:15 remaining] 71,  [1:13 remaining] 72,\n [1:10 remaining] 73,  [1:08 remaining] 74,  [1:05 remaining] 75,\n [1:02 remaining] 76,  [1:00 remaining] 77,  [57 sec remaining] 78,\n [55 sec remaining] 79,  [52 sec remaining] 80,  [50 sec remaining] 81,\n [47 sec remaining] 82,  [44 sec remaining] 83,  [42 sec remaining] 84,\n [39 sec remaining] 85,  [36 sec remaining] 86,  [34 sec remaining] 87,\n [31 sec remaining] 88,  [29 sec remaining] 89,  [26 sec remaining] 90,\n [23 sec remaining] 91,  [21 sec remaining] 92,  [18 sec remaining] 93,\n [16 sec remaining] 94,  [13 sec remaining] 95,  [10 sec remaining] 96,\n [8 sec remaining] 97,  [5 sec remaining] 98,  [3 sec remaining] \n99.\n\nDone.\n\nplot(K_battle.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nK_explosion.csr &lt;- envelope(conflict_sagaing_2024_ppp_list$`Explosions/Remote violence`, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [3:41 remaining] 3,\n [3:11 remaining] 4,  [3:10 remaining] 5,  [3:08 remaining] 6,\n [3:09 remaining] 7,  [3:04 remaining] 8,  [2:59 remaining] 9,\n [2:58 remaining] 10,  [2:56 remaining] 11,  [2:53 remaining] 12,\n [2:51 remaining] 13,  [2:50 remaining] 14,  [2:46 remaining] 15,\n [2:43 remaining] 16,  [2:43 remaining] 17,  [2:39 remaining] 18,\n [2:39 remaining] 19,  [2:37 remaining] 20,  [2:36 remaining] 21,\n [2:33 remaining] 22,  [2:33 remaining] 23,  [2:31 remaining] 24,\n [2:29 remaining] 25,  [2:27 remaining] 26,  [2:26 remaining] 27,\n [2:23 remaining] 28,  [2:22 remaining] 29,  [2:20 remaining] 30,\n [2:18 remaining] 31,  [2:16 remaining] 32,  [2:14 remaining] 33,\n [2:11 remaining] 34,  [2:09 remaining] 35,  [2:07 remaining] 36,\n [2:05 remaining] 37,  [2:03 remaining] 38,  [2:01 remaining] 39,\n [1:59 remaining] 40,  [1:58 remaining] 41,  [1:56 remaining] 42,\n [1:55 remaining] 43,  [1:53 remaining] 44,  [1:51 remaining] 45,\n [1:49 remaining] 46,  [1:47 remaining] 47,  [1:45 remaining] 48,\n [1:43 remaining] 49,  [1:41 remaining] 50,  [1:39 remaining] 51,\n [1:37 remaining] 52,  [1:35 remaining] 53,  [1:33 remaining] 54,\n [1:31 remaining] 55,  [1:29 remaining] 56,  [1:27 remaining] 57,\n [1:25 remaining] 58,  [1:22 remaining] 59,  [1:21 remaining] 60,\n [1:18 remaining] 61,  [1:16 remaining] 62,  [1:14 remaining] 63,\n [1:12 remaining] 64,  [1:10 remaining] 65,  [1:08 remaining] 66,\n [1:06 remaining] 67,  [1:04 remaining] 68,  [1:02 remaining] 69,\n [1:00 remaining] 70,  [58 sec remaining] 71,  [56 sec remaining] 72,\n [54 sec remaining] 73,  [52 sec remaining] 74,  [50 sec remaining] 75,\n [48 sec remaining] 76,  [46 sec remaining] 77,  [44 sec remaining] 78,\n [42 sec remaining] 79,  [40 sec remaining] 80,  [38 sec remaining] 81,\n [36 sec remaining] 82,  [34 sec remaining] 83,  [32 sec remaining] 84,\n [30 sec remaining] 85,  [28 sec remaining] 86,  [26 sec remaining] 87,\n [24 sec remaining] 88,  [22 sec remaining] 89,  [20 sec remaining] 90,\n [18 sec remaining] 91,  [16 sec remaining] 92,  [14 sec remaining] 93,\n [12 sec remaining] 94,  [10 sec remaining] 95,  [8 sec remaining] 96,\n [6 sec remaining] 97,  [4 sec remaining] 98,  [2 sec remaining] \n99.\n\nDone.\n\nplot(K_explosion.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nK_Strat.csr &lt;- envelope(conflict_sagaing_2024_ppp_list$`Strategic developments`, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [3:38 remaining] 3,\n [3:10 remaining] 4,  [3:03 remaining] 5,  [3:00 remaining] 6,\n [3:00 remaining] 7,  [3:00 remaining] 8,  [2:56 remaining] 9,\n [2:51 remaining] 10,  [2:47 remaining] 11,  [2:41 remaining] 12,\n [2:39 remaining] 13,  [2:35 remaining] 14,  [2:34 remaining] 15,\n [2:32 remaining] 16,  [2:30 remaining] 17,  [2:28 remaining] 18,\n [2:25 remaining] 19,  [2:25 remaining] 20,  [2:22 remaining] 21,\n [2:21 remaining] 22,  [2:18 remaining] 23,  [2:18 remaining] 24,\n [2:16 remaining] 25,  [2:14 remaining] 26,  [2:13 remaining] 27,\n [2:10 remaining] 28,  [2:08 remaining] 29,  [2:07 remaining] 30,\n [2:05 remaining] 31,  [2:05 remaining] 32,  [2:04 remaining] 33,\n [2:03 remaining] 34,  [2:01 remaining] 35,  [1:59 remaining] 36,\n [1:57 remaining] 37,  [1:55 remaining] 38,  [1:53 remaining] 39,\n [1:51 remaining] 40,  [1:49 remaining] 41,  [1:48 remaining] 42,\n [1:45 remaining] 43,  [1:44 remaining] 44,  [1:42 remaining] 45,\n [1:41 remaining] 46,  [1:39 remaining] 47,  [1:37 remaining] 48,\n [1:35 remaining] 49,  [1:33 remaining] 50,  [1:31 remaining] 51,\n [1:29 remaining] 52,  [1:28 remaining] 53,  [1:26 remaining] 54,\n [1:24 remaining] 55,  [1:22 remaining] 56,  [1:21 remaining] 57,\n [1:19 remaining] 58,  [1:17 remaining] 59,  [1:15 remaining] 60,\n [1:13 remaining] 61,  [1:12 remaining] 62,  [1:10 remaining] 63,\n [1:08 remaining] 64,  [1:06 remaining] 65,  [1:04 remaining] 66,\n [1:03 remaining] 67,  [1:01 remaining] 68,  [59 sec remaining] 69,\n [57 sec remaining] 70,  [55 sec remaining] 71,  [54 sec remaining] 72,\n [52 sec remaining] 73,  [50 sec remaining] 74,  [48 sec remaining] 75,\n [46 sec remaining] 76,  [44 sec remaining] 77,  [42 sec remaining] 78,\n [40 sec remaining] 79,  [38 sec remaining] 80,  [36 sec remaining] 81,\n [34 sec remaining] 82,  [32 sec remaining] 83,  [31 sec remaining] 84,\n [29 sec remaining] 85,  [27 sec remaining] 86,  [25 sec remaining] 87,\n [23 sec remaining] 88,  [21 sec remaining] 89,  [19 sec remaining] 90,\n [17 sec remaining] 91,  [15 sec remaining] 92,  [13 sec remaining] 93,\n [11 sec remaining] 94,  [10 sec remaining] 95,  [8 sec remaining] 96,\n [6 sec remaining] 97,  [4 sec remaining] 98,  [2 sec remaining] \n99.\n\nDone.\n\nplot(K_Strat.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nset.seed(448)\nK_violence.csr &lt;- envelope(conflict_sagaing_2024_ppp_list$`Violence against civilians`, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(K_violence.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\nLikewise it does show that the conflicts in 2024 are all generally clustered as it is above the envelope"
  },
  {
    "objectID": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#insights-1",
    "href": "Take-home_EX/Take-home_Ex01/Take-home_Ex01.html#insights-1",
    "title": "Take-home Exercise 1: Armed Conflict in Myanmar",
    "section": "Insights",
    "text": "Insights\nOur STKDE results confirm our initial KDE results in detailing clustered conflict event happening within Sagaing. Central Myanmar is also once again shown to be filled with conflicts."
  }
]